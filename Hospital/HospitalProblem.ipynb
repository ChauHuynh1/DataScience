{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b47204c",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#ffc0cb;font-size:70px;font-family:Georgia;text-align:center;\"><strong>Hospital Problem</strong></h1>\n",
    "\n",
    "### <b>Author: Nguyen Dang Huynh Chau</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddadbc81",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#ffc0cb;font-size:40px;font-family:Georgia;text-align:center;\"><strong> üìú Table of Content</strong></h1>\n",
    "\n",
    "### 1. [Data Preparation](#1)\n",
    "\n",
    "1.1 [Importing Necessary Libraries and datasets](#1.1)\n",
    "\n",
    "1.2 [Data Retrieving](#1.2)\n",
    "\n",
    "1.3 [Data information](#1.3)\n",
    "\n",
    "<br>\n",
    "\n",
    "### 2. [Data Cleaning](#2)\n",
    "\n",
    "2.1 [About This Dataset](#2.1)\n",
    "\n",
    "2.2 [Data Processing](#2.2)\n",
    "\n",
    "> - 2.2.1 [Drop Column](#2.2.1) \n",
    "> - 2.2.2 [Convert length of stay to 0 and 1](#2.2.2)\n",
    "> - 2.2.2 [Convert Unknown](#2.2.2)\n",
    "\n",
    "\n",
    "2.3 [Check missing values](#2.3)\n",
    "\n",
    "2.4 [Data type](#2.4)\n",
    "\n",
    "2.5 [Upper Case the content](#2.5)\n",
    "\n",
    "2.6 [Extra-whitespaces](#2.6)\n",
    "\n",
    "2.7 [Descriptive statistics for Central Tendency](#2.7)\n",
    "\n",
    "2.8 [Detect Outlier](#2.8)\n",
    "\n",
    "2.9 [Save The Intermediate Data](#2.9)\n",
    "\n",
    "<br>\n",
    "\n",
    "### 3. [Data Exploration (EDA)](#3)\n",
    "\n",
    "3.1 [Overall look on target variable](#3.1)\n",
    "\n",
    "> - 3.1.1 [Distribution of Length Of Stay](#3.1.1) \n",
    "> - 3.1.2 [Distribution of Length Of Stay](#3.1.2) \n",
    "\n",
    "3.2 [Frequency of each corresponiding Target variable type](#3.2)\n",
    "\n",
    "> - 3.2.1 [Medical Cost of both group stay more vs less than 3 days in Hospital](#3.2.1) \n",
    "> - 3.2.2 [Length of stay of each serverity of illness group](#3.2.2) \n",
    "> - 3.2.3 [Patient Gender Distribution - Stay less vs more than 3 days](#3.2.3) \n",
    "> - 3.2.4 [APR Severity Of Illness Code Distribution - Stay less vs more than 3 days](#3.2.4) \n",
    "> - 3.2.5 [Race Distribution - Stay less vs more than 3 days](#3.2.5) \n",
    "> - 3.2.6 [Severity of illness of each reaces](#3.2.6) \n",
    "> - 3.2.7 [Medical Cost of each Race in both group stay more vs less than 3 days in Hospital](#3.2.7) \n",
    "> - 3.2.8 [Medical Cost of each Severity of illness in both group stay more vs less than 3 days in Hospital](#3.2.8) \n",
    "> - 3.2.9 [Average hospitalization Cost Distribution Stay more vs less than 3 days](#3.2.9) \n",
    "> - 3.2.10 [Birth Weight Distribution - Stay more vs less than 3 days](#3.2.10) \n",
    "> - 3.2.11 [Average Charges In County Distribution - Stay more vs less than 3 days](#3.2.11) \n",
    "> - 3.2.12 [Average Cost In Facility Distribution - Stay more vs less than 3 days](#3.2.12) \n",
    "> - 3.2.13 [Average Charges In Facility Distribution - Stay more vs less than 3 days](#3.2.13) \n",
    "> - 3.2.14 [Factorplot of Average Charges In Facility Length Of Stay](#3.2.14) \n",
    "\n",
    "3.3 [Summary](#3.3)\n",
    "\n",
    "<br>\n",
    "\n",
    "### 4. [Statistic Overview](#4)\n",
    "\n",
    "4.1 [Descriptive statistics for Variability](#4.1)\n",
    "\n",
    "4.2 [Correlation Matrix and Heatmap](#4.2)\n",
    "\n",
    "> 4.2.1 [Correlation Matrix](#4.2.1)\n",
    "\n",
    "> 4.2.2 [Heat map](#4.2.2)\n",
    "\n",
    "4.3 [Statistical Test for Correlation](#4.3)\n",
    "\n",
    "<br>\n",
    "\n",
    "### 5. [Feature Engineering](#5) \n",
    "\n",
    "5.1 [Encoding](#5.1)\n",
    "\n",
    "5.2 [Separating dependent and independent variables](#5.2)\n",
    "\n",
    "5.3 [Splitting the training data](#5.3)\n",
    "\n",
    "5.4 [Feature Scaling](#5.4)\n",
    "\n",
    "<br>\n",
    "\n",
    "### 6. [Model Building](#6) \n",
    "\n",
    "5.1 [Logistic Regression](#5.1)\n",
    "\n",
    "5.1 [Feature Scaling](#5.2)\n",
    "\n",
    "5.1 [Feature Scaling](#5.3)\n",
    "\n",
    "5.1 [Feature Scaling](#5.4)\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "### 7. [Conculsions](#7)\n",
    "\n",
    "<br>\n",
    "\n",
    "### 8. [References](#8)\n",
    "\n",
    "<br>\n",
    "\n",
    "### 9. [Appendix](#9)\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc61406c",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "<h1 style=\"color:#ffc0cb;font-size:40px;font-family:Georgia;text-align:center;\"><strong> ‚úçÔ∏è 1. Data Preparation</strong></h1>\n",
    "\n",
    "<a id=\"1.1\"></a>\n",
    "# ‚ú¥Ô∏è 1.1 Importing Necessary Libraries and datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f53228",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Install a conda package in the current Jupyter kernel\n",
    "import sys\n",
    "!{sys.executable} -m pip install missingno\n",
    "!{sys.executable} -m pip install scikit-learn\n",
    "!{sys.executable} -m pip install xgboost\n",
    "!{sys.executable} -m pip install statsmodels\n",
    "!{sys.executable} -m pip install imbalanced-learn\n",
    "!{sys.executable} -m pip install category_encoders\n",
    "\n",
    "# work with data in tabular representation\n",
    "from datetime import time\n",
    "import pandas as pd\n",
    "# round the data in the correlation matrix\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "# Modules for data visualization\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import plot_confusion_matrix, classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# encoding\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "import category_encoders as ce\n",
    "\n",
    "# import LogisticRegression model in python. \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_absolute_error, accuracy_score\n",
    "\n",
    "# for saving the pipeline\n",
    "import joblib\n",
    "\n",
    "# from Scikit-learn\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, Binarizer\n",
    "\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', 200)\n",
    "\n",
    "# Ensure that our plots are shown and embedded within the Jupyter notebook itself. Without this command, sometimes plots may show up in pop-up windows\n",
    "%matplotlib inline\n",
    "\n",
    "# overwrite the style of all the matplotlib graphs\n",
    "sns.set()\n",
    "\n",
    "# ignore DeprecationWarning Error Messages\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a351936b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the version of the packages\n",
    "print(\"Numpy version: \", np.__version__)\n",
    "print(\"Pandas version: \",pd.__version__)\n",
    "! python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d777b242",
   "metadata": {},
   "source": [
    "<a id=\"1.2\"></a>\n",
    "# üì≤ 1.2 Data Retrieving\n",
    "***\n",
    "In order to load data properly, the data in csv file have to be examined carefully. First of all, all the categories are seperated by the \",\" and strip the extra-whitespaces at the begin by setting \"skipinitialspace = True\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785d789a",
   "metadata": {},
   "source": [
    "> **Sample train Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cad3d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing the datasets\n",
    "train = pd.read_csv(\"Data/train_data.csv\", delimiter=',', skipinitialspace = True)\n",
    "\n",
    "train.columns = train.columns.str.replace(' ', '') #strip the extra-whitespaces out\n",
    "\n",
    "print(\"The shape of the ORGINAL data is (row, column):\", str(train.shape))\n",
    "\n",
    "# drop Unnamed, it is just a number given to identify each house\n",
    "train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d68f273",
   "metadata": {},
   "source": [
    "> **Sample test Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777cb0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"Data/test_data.csv\", delimiter=',', skipinitialspace = True)\n",
    "\n",
    "test.columns = test.columns.str.replace(' ', '') #strip the extra-whitespaces out\n",
    "\n",
    "print(\"The shape of the ORGINAL data is (row, column):\", str(test.shape))\n",
    "\n",
    "# drop Unnamed, it is just a number given to identify each house\n",
    "test.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe1ec8a",
   "metadata": {},
   "source": [
    "<a id=\"1.3\"></a>\n",
    "# üîà 1.3 Data Information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e1e235",
   "metadata": {},
   "source": [
    "> **Sample train Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b531feb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"The shape of the train data is (row, column):\"+ str(train.shape))\n",
    "print (train.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77c5e59",
   "metadata": {},
   "source": [
    "> **Sample test Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2fd89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"The shape of the test data is (row, column):\"+ str(test.shape))\n",
    "print (test.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b33704d",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a>\n",
    "<h1 style=\"color:#ffc0cb;font-size:40px;font-family:Georgia;text-align:center;\"><strong> üßπ 2. Data Cleaning</strong></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec13ea35",
   "metadata": {},
   "source": [
    "<a id=\"2.1\"></a>\n",
    "# ü¶Ñ 2.1 About This Dataset\n",
    "***\n",
    "The dataset is splitted into two groups:\n",
    "- Train set (train.csv)\n",
    "- Test set (test.csv)\n",
    "\n",
    "Now let's go through the features and describe a little:\n",
    "***\n",
    "**Categorical:** \n",
    "- **Nominal**(variables that have two or more categories, but which do not have an intrinsic order.)\n",
    "   > - **HealthServiceArea** (A description of the Health Service Area (HSA) in which the hospital is located)\n",
    "   > - **TypeOfAdmission** \n",
    "   (A description of   the manner in which the patient was admitted to the health care facility)\n",
    "            Newborn\n",
    "            Emergency \n",
    "            Urgent\n",
    "            Elective\n",
    "   > - **Race** (Patient race)\n",
    "            White\n",
    "            Other Race \n",
    "            Black/African American\n",
    "            Multi-racial\n",
    "   > - **PaymentTypology** (A description of the type of payment for this occurrence.)\n",
    "        \n",
    "- **Dichotomous**(Nominal variable with only two categories)\n",
    "   > - **Gender**\n",
    "            F\n",
    "            M\n",
    "   > - **EmergencyDepartmentIndicator** \n",
    "   (Emergency Department Indicator is set based on the submitted revenue codes. If the record contained an Emergency       Department revenue code of 045X)\n",
    "            Y\n",
    "            N\n",
    "***\n",
    "**Numeric:**\n",
    "- **Discrete**\n",
    "  >  - **ID**(Unique identifing # for each passenger)\n",
    "  >  - **CCSProcedureCode** (AHRQ Clinical Classification Software (CCS) ICD-9 Procedure Category Code)\n",
    "  >  - **APRSeverityOfIllnessCode** (All Patient  Refined Severity of Illness (APR SOI) Description) \n",
    "             Minor (1)\n",
    "             Moderate (2)   \n",
    "             Major (3)\n",
    "             Extreme (4))\n",
    "  >  - **LengthOfStay** (The total number  of patient days at an acute level and/or other than acute care level.)\n",
    "\n",
    "- **Continous**\n",
    ">  - **BirthWeight** (The neonate birth weight in grams; rounded to nearest)\n",
    ">  - **AverageCostInCounty** (Average hospitalization Cost In County of the patient)\n",
    ">  - **AverageChargesInCounty** (Average medical Charges In County of the patient)\n",
    ">  - **AverageCostInFacility** (Average Cost In Facility)\n",
    ">  - **AverageChargesInFacility** (Average Charges cost In Facility)\n",
    ">  - **AverageIncomeInZipCode** (Average Income In Zip Code)\n",
    ">  - **LengthOfStay** (The total number  of patient days at an acute level and/or other than acute care level.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c97fe64",
   "metadata": {},
   "source": [
    "<a id=\"2.2\"></a>\n",
    "# ‚ùå 2.2 Data preprocessing\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a83de4e",
   "metadata": {},
   "source": [
    "<a id=\"2.2.1\"></a>\n",
    "## 2.2.1 Drop column\n",
    "***\n",
    "- In order to avoid data leakage, I desire to drop column `ID`.\n",
    "- I also desire to drop `HealthServiceArea` since it does not contain the specific location, and there is no correlation between `HealthServiceArea` and `LengthOfStay`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8148875e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(columns=['ID', 'HealthServiceArea', 'AverageIncomeInZipCode'])\n",
    "test = test.drop(columns=['ID', 'HealthServiceArea', 'AverageIncomeInZipCode'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8012824b",
   "metadata": {},
   "source": [
    "<a id=\"2.2.2\"></a>\n",
    "## 2.2.2 Convert length of stay to 0 and 1\n",
    "***\n",
    "Since the requirement is to predict whether the paintient is stay in the hospital longer than 3 days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfbdda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['LengthOfStay'] = train['LengthOfStay'].apply(lambda x: 1 if x > 3 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53630b7c",
   "metadata": {},
   "source": [
    "<a id=\"2.2.3\"></a>\n",
    "## 2.2.3 Convert Unknown\n",
    "***\n",
    "Since the `Gender` column still has only one values `U`, I do not think it will effect the values so I decided to convert it to `F`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a43ed9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[train['Gender'].isin(['U']), 'Gender'] = 'F'\n",
    "test.loc[test['Gender'].isin(['U']), 'Gender'] = 'F'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef0e9d9",
   "metadata": {},
   "source": [
    "<a id=\"2.2.4\"></a>\n",
    "## 2.2.4 Check column contains\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f08cf5b",
   "metadata": {},
   "source": [
    "> **Gender column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8a2888",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = list(train['Gender'].value_counts().index)\n",
    "\n",
    "for x in range(len(categories)):\n",
    "    print (categories[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd54422b",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = list(test['Gender'].value_counts().index)\n",
    "\n",
    "for x in range(len(categories)):\n",
    "    print (categories[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024ec7f0",
   "metadata": {},
   "source": [
    "### ------> OBSERVATION\n",
    "*****\n",
    "I want to replace `M` with `Male` and `F` with `Female`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a13654",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train dataset\n",
    "train.loc[train['Gender'].isin(['F']), 'Gender'] = 'Female'\n",
    "train.loc[train['Gender'].isin(['M']), 'Gender'] = 'Male'\n",
    "\n",
    "#Test dataset\n",
    "test.loc[test['Gender'].isin(['F']), 'Gender'] = 'Female'\n",
    "test.loc[test['Gender'].isin(['M']), 'Gender'] = 'Male'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d616c7e",
   "metadata": {},
   "source": [
    "> **Race column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa30dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = list(train['Race'].value_counts().index)\n",
    "\n",
    "for x in range(len(categories)):\n",
    "    print (categories[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6471d5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = list(test['Race'].value_counts().index)\n",
    "\n",
    "for x in range(len(categories)):\n",
    "    print (categories[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a07c769",
   "metadata": {},
   "source": [
    "> **TypeOfAdmission column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5731b08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = list(train['TypeOfAdmission'].value_counts().index)\n",
    "\n",
    "for x in range(len(categories)):\n",
    "    print (categories[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f0e8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = list(test['TypeOfAdmission'].value_counts().index)\n",
    "\n",
    "for x in range(len(categories)):\n",
    "    print (categories[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13688c24",
   "metadata": {},
   "source": [
    "> **CCSProcedureCode column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230300c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = list(train['CCSProcedureCode'].value_counts().index)\n",
    "\n",
    "for x in range(len(categories)):\n",
    "    print (categories[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d09556",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = list(test['CCSProcedureCode'].value_counts().index)\n",
    "\n",
    "for x in range(len(categories)):\n",
    "    print (categories[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a5ccf2",
   "metadata": {},
   "source": [
    "### ------> OBSERVATION\n",
    "*****\n",
    "### ***Some Domain Knowledge:***\n",
    "<br>\n",
    "According to an official website of the Department of Health & Human Services, developed at the Agency for Healthcare Research and Quality (AHRQ), the Clinical Classifications Software (CCS) is a tool for clustering patient diagnoses and procedures into a manageable number of clinically meaningful categories. CCS offers researchers the ability to group conditions and procedures without having to sort through thousands of codes. This \"clinical grouper\" makes it easier to quickly understand patterns of diagnoses and procedures so that health plans, policy makers, and researchers can analyze costs, utilization, and outcomes associated with particular illnesses and procedures.\n",
    "\n",
    "> ----> There is a value `-1` which is not belong to the CCSProcedureCode list. So I desire to replace it with number `1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6b4027",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train dataset\n",
    "train.loc[train['CCSProcedureCode'] == -1 , 'CCSProcedureCode'] = 1\n",
    "\n",
    "#Test dataset\n",
    "test.loc[test['CCSProcedureCode'] == -1 , 'CCSProcedureCode'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26ad0a4",
   "metadata": {},
   "source": [
    "> **APRSeverityOfIllnessCode column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cf0c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = list(train['APRSeverityOfIllnessCode'].value_counts().index)\n",
    "\n",
    "for x in range(len(categories)):\n",
    "    print (categories[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0059da19",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = list(test['APRSeverityOfIllnessCode'].value_counts().index)\n",
    "\n",
    "for x in range(len(categories)):\n",
    "    print (categories[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d6f5f9",
   "metadata": {},
   "source": [
    "> **PaymentTypology column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2617bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = list(train['PaymentTypology'].value_counts().index)\n",
    "\n",
    "for x in range(len(categories)):\n",
    "    print (categories[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b42e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = list(test['PaymentTypology'].value_counts().index)\n",
    "\n",
    "for x in range(len(categories)):\n",
    "    print (categories[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa8b1cc",
   "metadata": {},
   "source": [
    "> **BirthWeight column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8f32f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.boxplot('BirthWeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba013838",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.boxplot('BirthWeight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c7d3cf",
   "metadata": {},
   "source": [
    "> **EmergencyDepartmentIndicator column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b79eb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = list(train['EmergencyDepartmentIndicator'].value_counts().index)\n",
    "\n",
    "for x in range(len(categories)):\n",
    "    print (categories[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365c2cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = list(test['EmergencyDepartmentIndicator'].value_counts().index)\n",
    "\n",
    "for x in range(len(categories)):\n",
    "    print (categories[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a53ee6",
   "metadata": {},
   "source": [
    "> **AverageCostInCounty column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6e89af",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.boxplot('AverageCostInCounty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20942ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.boxplot('AverageCostInCounty')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d1c66d",
   "metadata": {},
   "source": [
    "> **AverageChargesInCounty column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be0b3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.boxplot('AverageChargesInCounty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df4e288",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.boxplot('AverageChargesInCounty')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db88455",
   "metadata": {},
   "source": [
    "> **AverageCostInFacility column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e16a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.boxplot('AverageCostInFacility')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5939487f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.boxplot('AverageCostInFacility')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52e6df0",
   "metadata": {},
   "source": [
    "> **AverageChargesInFacility column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2890e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.boxplot('AverageChargesInFacility')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c516556a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.boxplot('AverageChargesInFacility')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763a3816",
   "metadata": {},
   "source": [
    "<a id=\"2.3\"></a>\n",
    "# üîç 2.3 Check missing values:\n",
    "Missing values can cause a lot of unexpected problems such as not reducing the power of a model, but also negatively affect the performance of the studies and analysis of that data. Hence, it is important to deal with missing data. First step is to check the number of missing values of each column and fill in with the appropriate values. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc10553",
   "metadata": {},
   "source": [
    "> **Sample train Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4feb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_percentage(df):\n",
    "    \"\"\"This function takes a DataFrame(df) as input and returns two columns, total missing values and total missing values percentage\"\"\"\n",
    "    total = df.isnull().sum().sort_values(ascending=False)[df.isnull().sum().sort_values(ascending=False) != 0]\n",
    "    percent = round(df.isnull().sum().sort_values(ascending=False) / len(df) * 100, 2)[\n",
    "        round(df.isnull().sum().sort_values(ascending=False) / len(df) * 100, 2) != 0]\n",
    "    return pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "\n",
    "# display missing values in descending\n",
    "print(\"Missing values in the dataframe in descending: \\n\", missing_percentage(train).sort_values(by='Total', ascending=False))\n",
    "\n",
    "# visualize where the missing values are located\n",
    "msno.matrix(train, color=(255 / 255, 192 / 255, 203 / 255))\n",
    "pink_patch = mpatches.Patch(color='pink', label='present value')\n",
    "white_patch = mpatches.Patch(color='white', label='absent value')\n",
    "plt.legend(handles=[pink_patch, white_patch])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11e9fc5",
   "metadata": {},
   "source": [
    "> **Sample test Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a837f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_percentage(df):\n",
    "    \"\"\"This function takes a DataFrame(df) as input and returns two columns, total missing values and total missing values percentage\"\"\"\n",
    "    total = df.isnull().sum().sort_values(ascending=False)[df.isnull().sum().sort_values(ascending=False) != 0]\n",
    "    percent = round(df.isnull().sum().sort_values(ascending=False) / len(df) * 100, 2)[\n",
    "        round(df.isnull().sum().sort_values(ascending=False) / len(df) * 100, 2) != 0]\n",
    "    return pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "\n",
    "# display missing values in descending\n",
    "print(\"Missing values in the dataframe in descending: \\n\", missing_percentage(test).sort_values(by='Total', ascending=False))\n",
    "\n",
    "# visualize where the missing values are located\n",
    "msno.matrix(test, color=(255 / 255, 192 / 255, 203 / 255))\n",
    "pink_patch = mpatches.Patch(color='pink', label='present value')\n",
    "white_patch = mpatches.Patch(color='white', label='absent value')\n",
    "plt.legend(handles=[pink_patch, white_patch])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce920a2",
   "metadata": {},
   "source": [
    "### ------> OBSERVATION\n",
    "*****\n",
    "Suprisingly, there is no missing data in both of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53121691",
   "metadata": {},
   "source": [
    "<a id=\"2.4\"></a>\n",
    "# ü¶Ñ 2.4 Data type\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db2ebbc",
   "metadata": {},
   "source": [
    "> **Sample train Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6caab70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['TypeOfAdmission'] = train['TypeOfAdmission'].astype('string')\n",
    "train['Race'] = train['Race'].astype('string')\n",
    "train['PaymentTypology'] = train['PaymentTypology'].astype('string')\n",
    "train['Gender'] = train['Gender'].astype('string')\n",
    "train['EmergencyDepartmentIndicator'] = train['EmergencyDepartmentIndicator'].astype('string')\n",
    "train['CCSProcedureCode'] = train['CCSProcedureCode'].astype('int')\n",
    "train['APRSeverityOfIllnessCode'] = train['APRSeverityOfIllnessCode'].astype('int')\n",
    "train['LengthOfStay'] = train['LengthOfStay'].astype('int')\n",
    "train['BirthWeight'] = train['BirthWeight'].astype('int')\n",
    "train['AverageCostInCounty'] = train['AverageCostInCounty'].astype('int')\n",
    "train['AverageChargesInCounty'] = train['AverageChargesInCounty'].astype('int')\n",
    "train['AverageCostInFacility'] = train['AverageCostInFacility'].astype('int')\n",
    "train['AverageChargesInFacility'] = train['AverageChargesInFacility'].astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec899f4",
   "metadata": {},
   "source": [
    "> **Sample test Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c30ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['TypeOfAdmission'] = test['TypeOfAdmission'].astype('string')\n",
    "test['Race'] = test['Race'].astype('string')\n",
    "test['PaymentTypology'] = test['PaymentTypology'].astype('string')\n",
    "test['Gender'] = test['Gender'].astype('string')\n",
    "test['EmergencyDepartmentIndicator'] = test['EmergencyDepartmentIndicator'].astype('string')\n",
    "test['CCSProcedureCode'] = test['CCSProcedureCode'].astype('int')\n",
    "test['APRSeverityOfIllnessCode'] = test['APRSeverityOfIllnessCode'].astype('int')\n",
    "test['BirthWeight'] = test['BirthWeight'].astype('int')\n",
    "test['AverageCostInCounty'] = test['AverageCostInCounty'].astype('int')\n",
    "test['AverageChargesInCounty'] = test['AverageChargesInCounty'].astype('int')\n",
    "test['AverageCostInFacility'] = test['AverageCostInFacility'].astype('int')\n",
    "test['AverageChargesInFacility'] = test['AverageChargesInFacility'].astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce258ee9",
   "metadata": {},
   "source": [
    "<a id=\"2.5\"></a>\n",
    "# üí≠ 2.5 Upper Case the content\n",
    "In this section we will convert all the string value in the column to uppercase for further processing and keep all the string uniformly format. This will improve the analysis of the data, and also easier to perform any function related to the string. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec17f40",
   "metadata": {},
   "source": [
    "> **Sample train Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330bd96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast all values inside the dataframe (except the columns' name) into upper case.\n",
    "train = train.applymap(lambda s: s.upper() if type(s) == str else s)\n",
    "train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27c94d5",
   "metadata": {},
   "source": [
    "> **Sample test Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c00641f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast all values inside the dataframe (except the columns' name) into upper case.\n",
    "test = test.applymap(lambda s: s.upper() if type(s) == str else s)\n",
    "test.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aef9257",
   "metadata": {},
   "source": [
    "<a id=\"2.6\"></a>\n",
    "# üìö 2.6 Extra-whitespaces:\n",
    "***\n",
    "There are some time maybe an extra-whitespaces in the database, which results in comparison failures, NaN Value, and greater size. First of all, extra-whitespaces cause string with and without it to not be the same. For instance, \"ABC\" != \" ABC\", these two strings are not equal, and that mistake cannot be noticed straightforwardly since the difference is inconsiderable. Nevertheless, the computer cannot understand that mistake. Secondly, the extra-whitespaces can be record as NaN values in pandas, which results in unexpected result. Last but not least, the whitespaces can increase the size of the database so that they can overflow the limited size. So that data should be checked with extra-whitespaces carefully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f11076b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def whitespace_remover(df):\n",
    "    \"\"\"\n",
    "    The function will remove extra leading and trailing whitespace from the data.\n",
    "    \"\"\"\n",
    "    # iterating over the columns\n",
    "    for i in df.columns:\n",
    "        # checking datatype of each columns\n",
    "        if df[i].dtype == 'object' or df[i].dtype == 'str':\n",
    "            # applying strip function on column\n",
    "            df[i] = df[i].map(str.strip)\n",
    "        else:\n",
    "            # if condition is False then it will do nothing.\n",
    "            pass\n",
    "\n",
    "# remove all the extra whitespace\n",
    "whitespace_remover(train)\n",
    "whitespace_remover(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea576fc",
   "metadata": {},
   "source": [
    "<a id=\"2.7\"></a>\n",
    "# üìä 2.7 Descriptive statistics for Central Tendency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad01ca2",
   "metadata": {},
   "source": [
    "> **Sample train Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92f8dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see the static of all numerical column\n",
    "train.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08617c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [20, 15]\n",
    "# plot the boxplot to see the outlier of each numerical column\n",
    "sns.boxplot(data=train,orient=\"h\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662714e0",
   "metadata": {},
   "source": [
    "### ---------> OBSERVATION\n",
    "> For all numerical columns, I see some outlier values in `AverageCostInFacility` and `BirthWeight`. Let's investigate them further to see if they are real outliers or not using statistical techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aad3ae3",
   "metadata": {},
   "source": [
    "> **Sample test Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432a53c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see the static of all numerical column\n",
    "train.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62543086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the boxplot to see the outlier of each numerical column\n",
    "sns.boxplot(data=test,orient=\"h\")\n",
    "plt.rcParams['figure.figsize'] = [20, 15]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6492874e",
   "metadata": {},
   "source": [
    "### ---------> OBSERVATION\n",
    "> For all numerical columns, I see some outlier values in `BirthWeight`. Let's investigate them further to see if they are real outliers or not using statistical techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e4e587",
   "metadata": {},
   "source": [
    "<a id=\"2.8\"></a>\n",
    "# üí¢ 2.8 Detect Outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e251ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.boxplot('BirthWeight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e4246f",
   "metadata": {},
   "source": [
    "### ---------> OBSERVATION\n",
    "****\n",
    "The newborn child who weight nearly and more than 7000 seem to be rare but it's still acceptable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d2ac67",
   "metadata": {},
   "source": [
    "<a id=\"2.9\"></a>\n",
    "# üìÇ 2.9 Save the Intermediate data\n",
    "***\n",
    "After the cleaning step, all data is saved to a csv file for visualisation step later in dash."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5601497b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(\"Data/train_cleaned.csv\", encoding='utf-8')\n",
    "test.to_csv(\"Data/test_cleaned.csv\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4222a99",
   "metadata": {},
   "source": [
    "<a id=\"3\"></a>\n",
    "<h1 style=\"color:#ffc0cb;font-size:40px;font-family:Georgia;text-align:center;\"><strong> üìä 3. Data exploration (EDA)</strong></h1>\n",
    "\n",
    "**Assumptions:**\n",
    "- **LengthOfStay**: The number of people who stay more than 3 days in the hospital is higher than the people who stay less than 3 days.\n",
    "- **AverageCostInCounty**: the people who stay more than 3 days in the hospital have to pay a higher cost.\n",
    "- **Gender**: More female survived than male, and the number of female stay in the hospital more than 3 days is higher than male \n",
    "- **APRSeverityOfIllnessCode**: the number of patient having the extreme severity is higher. The more serious illness that a patient have, the higher money they have to pay.\n",
    "- **Race**: the number of medical cost the Black/African American have to pay higher than others, and the White people pay the lowest cost. Hence, the number of White patient is the highest.\n",
    "\n",
    "Now, let's see how the features are related to each other by creating some visualizations. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7c1ece",
   "metadata": {},
   "source": [
    "<a id=\"3.1\"></a>\n",
    "# 3.1 Overall look on target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089b1029",
   "metadata": {},
   "source": [
    "<a id=\"3.1.1\"></a>\n",
    "## 3.1.1 Distribution of Length Of Stay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea13cba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.displot(train, x=\"Survived\", hue=\"Pclass\", kind=\"kde\", fill=True)\n",
    "plot = sns.displot(train, x=\"LengthOfStay\", kind=\"kde\", fill=True, color='blue', height= 14)\n",
    "\n",
    "\n",
    "plot.fig.suptitle(\"Distribution of Length Of Stay\", fontsize=25, y=1.08, fontweight = 'bold')\n",
    "plot.set_xlabels(\"Length Of Stay\", fontsize = 20, fontweight = 'bold' )\n",
    "plot.set_ylabels(\"Density\", fontsize = 20, fontweight = 'bold')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49598852",
   "metadata": {},
   "source": [
    "### ---------> OBSERVATION\n",
    "***\n",
    "- It is a bionormal distribution\n",
    "- More people stay more than 3 days than people stay in the hospital less than 3 days."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec30509a",
   "metadata": {},
   "source": [
    "<a id=\"3.1.2\"></a>\n",
    "## 3.1.2 Proportion of length of stay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7e0600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pie chart\n",
    "labels = ['Stay less than 3 days', 'Stay more than 3 days']\n",
    "#colors\n",
    "colors = ['#94B3FD', '#F9C5D5']\n",
    "ax = plt.pie(train['LengthOfStay'].value_counts(), labels=labels, labeldistance=1.15, colors=colors, autopct='%1.1f%%', textprops={'fontsize': 16});\n",
    "plt.title('Proportion of length of stay', fontsize=25, fontweight = 'bold')\n",
    "plt.rcParams['figure.figsize'] = [20, 15]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55c489b",
   "metadata": {},
   "source": [
    "### ---------> OBSERVATION\n",
    "***\n",
    "This pie plot is chosen to demonstrates the proportion of people stay less than 3 days vs people stay more than 3 days. Overall, stay in the hospital less than 3 days is the most common options for pantents accounts for more than 83 percent, while just only nearly 17 percent of patient choose to stay more than 3 days. The number people stay less than 3 days is nearly 8 time higher than those people who stay more than 3 days."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4edd3d",
   "metadata": {},
   "source": [
    "<a id=\"3.2\"></a>\n",
    "# 3.2 Frequency of each corresponiding Target variable type\n",
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a204159",
   "metadata": {},
   "source": [
    "<a id=\"3.2.1\"></a>\n",
    "## 3.2.1 Medical Cost of both group stay more vs less than 3 days in Hospital\n",
    "****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff81581",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"darkgrid\")\n",
    "\n",
    "plot = sns.catplot(data=train, kind=\"bar\", x=\"LengthOfStay\", y=\"AverageCostInCounty\", height = 10)\n",
    "\n",
    "plot.fig.suptitle(\"Medical Cost of both group stay more vs less than 3 days in Hospital\", fontsize=25, y=1.08, fontweight = 'bold')\n",
    "plot.set_xlabels(\"Length Of Stay\", fontsize = 20, fontweight = 'bold' )\n",
    "plot.set_ylabels(\"Medical Cost\", fontsize = 20, fontweight = 'bold')\n",
    "plt.rcParams['figure.figsize'] = [20, 15]\n",
    "plot.set_xticklabels(['More than 3 days', 'Less than 3 days'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2175d775",
   "metadata": {},
   "source": [
    "### ---------> OBSERVATION\n",
    "***\n",
    "This bar chart demonstrates the medical cost that both group stay more than 3 days and stay less than 3 days have to pay for the hospital, it is chosen since it can compare the magnitude between the number of people who stay more than 3 days and stay less than 3 day. Same as we expected, the group stay more than 3 days have to pay more medical cost than the group stay less than 3 days."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2039db6f",
   "metadata": {},
   "source": [
    "<a id=\"3.2.2\"></a>\n",
    "## 3.2.2 Length of stay of each serverity of illness group\n",
    "****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76be512d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"darkgrid\")\n",
    "\n",
    "plot = sns.catplot(data=train, kind=\"bar\", x=\"APRSeverityOfIllnessCode\", y=\"LengthOfStay\", height = 10)\n",
    "\n",
    "plot.fig.suptitle(\"Length of stay of each serverity of each illness group\", fontsize=25, y=1.08, fontweight = 'bold')\n",
    "plot.set_xlabels(\"Severity Of Illness\", fontsize = 20, fontweight = 'bold' )\n",
    "plot.set_ylabels(\"Length Of Stay\", fontsize = 20, fontweight = 'bold')\n",
    "plt.rcParams['figure.figsize'] = [20, 15]\n",
    "plot.set_xticklabels(['Minor', 'Moderate', 'Major', 'Extreme'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ca9fc4",
   "metadata": {},
   "source": [
    "### ---------> OBSERVATION\n",
    "***\n",
    "According to this bar chart, the severity of illness number 4 stay in the hospital more than 3 days, while the patient having the severity number 1 stay in the hospital less than 3 days."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fd74a9",
   "metadata": {},
   "source": [
    "<a id=\"3.2.3\"></a>\n",
    "## 3.2.3 Patient Gender Distribution - Stay less vs more than 3 days\n",
    "****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce208daf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pal = {1:\"pink\", 0:\"blue\"}\n",
    "sns.set(style=\"darkgrid\")\n",
    "plt.subplots(figsize = (15,8))\n",
    "ax = sns.countplot(x = \"Gender\", \n",
    "                   hue=\"LengthOfStay\",\n",
    "                   data = train, \n",
    "                   linewidth=4, \n",
    "                   palette = pal\n",
    ")\n",
    "\n",
    "## Fixing title, xlabel and ylabel\n",
    "plt.title(\"Patient Gender Distribution - Stay less vs more than 3 days\", fontsize = 20, fontweight = 'bold', pad=40)\n",
    "plt.xlabel(\"Gender\", fontsize = 20, fontweight = 'bold');\n",
    "plt.ylabel(\"Number of Patient\", fontsize = 20, fontweight = 'bold')\n",
    "\n",
    "## Fixing legends\n",
    "leg = ax.get_legend()\n",
    "leg.set_title(\"Length Of Stay\")\n",
    "legs = leg.texts\n",
    "legs[0].set_text(\"Stay more than 3 days\")\n",
    "legs[1].set_text(\"Stay less than 3 days\")\n",
    "plt.show()\n",
    "plt.rcParams['figure.figsize'] = [20, 15]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563064f1",
   "metadata": {},
   "source": [
    "### ---------> OBSERVATION\n",
    "***\n",
    "This bar chart is chosen since it can compare the magnitude between the number of people who stay more than 3 days and stay less than 3 days in both genders male and female. Overall, the number of gender is approximately equal, the male is unconsiderably higher a little bit. Hence, my assumption there are more female than male is incorrect. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8de5552",
   "metadata": {},
   "source": [
    "<a id=\"3.2.4\"></a>\n",
    "## 3.2.4 APR Severity Of Illness Code Distribution - Stay less vs more than 3 days\n",
    "****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be2955f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"darkgrid\")\n",
    "plt.subplots(figsize = (15,8))\n",
    "ax = sns.countplot(x = \"APRSeverityOfIllnessCode\", \n",
    "                   hue=\"LengthOfStay\",\n",
    "                   data = train, \n",
    "                   linewidth=4)\n",
    "\n",
    "## Fixing title, xlabel and ylabel\n",
    "plt.title(\"APR Severity Of Illness Code Distribution - Stay less vs more than 3 days\", fontsize = 20, fontweight = 'bold', pad=40)\n",
    "plt.xlabel(\"Severity Of Illness\", fontsize = 20, fontweight = 'bold');\n",
    "plt.ylabel(\"Number of Patient\", fontsize = 20, fontweight = 'bold')\n",
    "\n",
    "## Fixing legends\n",
    "leg = ax.get_legend()\n",
    "leg.set_title(\"Length Of Stay\")\n",
    "legs = leg.texts\n",
    "legs[0].set_text(\"Stay less than 3 days\")\n",
    "legs[1].set_text(\"Stay more than 3 days\")\n",
    "plt.show()\n",
    "plt.rcParams['figure.figsize'] = [20, 15]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e40242e",
   "metadata": {},
   "source": [
    "### ---------> OBSERVATION\n",
    "***\n",
    "This bar chart displays the number of people in each APR Severity of Illness, it is chosen since it can compare the magnitude between the number people between 4 different severity of illness. Overall, the group severity of illness level 1 has the highest number of patient and they tend to stay in the hospital less than 3 days. Because of that, my assumption for the `APRSeverityOfIllnessCode` is incorrect since the the number of patient having the extreme severity is lower. Moreover, it is just a sample data so that it may be because it is collected from a hospital which do not have enough professional doctors to deal with the extreme illness."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf55e3f",
   "metadata": {},
   "source": [
    "<a id=\"3.2.5\"></a>\n",
    "## 3.2.5 Race Distribution - Stay less vs more than 3 days\n",
    "****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3740ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"darkgrid\")\n",
    "plt.subplots(figsize = (15,8))\n",
    "ax = sns.countplot(x = \"Race\", \n",
    "                   hue=\"LengthOfStay\",\n",
    "                   data = train, \n",
    "                   linewidth=4)\n",
    "\n",
    "## Fixing title, xlabel and ylabel\n",
    "plt.title(\"Race Distribution - Stay less vs more than 3 days\", fontsize = 20, fontweight = 'bold', pad=40)\n",
    "plt.xlabel(\"Race\", fontsize = 20, fontweight = 'bold');\n",
    "plt.ylabel(\"Number of Patient\", fontsize = 20, fontweight = 'bold')\n",
    "\n",
    "## Fixing legends\n",
    "leg = ax.get_legend()\n",
    "leg.set_title(\"Length Of Stay\")\n",
    "legs = leg.texts\n",
    "legs[0].set_text(\"Stay less than 3 days\")\n",
    "legs[1].set_text(\"Stay more than 3 days\")\n",
    "plt.show()\n",
    "plt.rcParams['figure.figsize'] = [20, 15]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7316853c",
   "metadata": {},
   "source": [
    "### ---------> OBSERVATION\n",
    "***\n",
    "This count bar plot illustrates the number of patient by races and the day they stay in the hospital. Overall, same as we expected, most of the patients are the white people. Although this is just the sample data but, let's find out the reason the why the Black/Afrian American do not have people stay hospital."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b353ceb7",
   "metadata": {},
   "source": [
    "<a id=\"3.2.6\"></a>\n",
    "## 3.2.6 Severity of illness of each reaces\n",
    "****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c06747",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"darkgrid\")\n",
    "plt.subplots(figsize = (15,8))\n",
    "ax = sns.countplot(x = \"Race\", \n",
    "                   hue=\"APRSeverityOfIllnessCode\",\n",
    "                   data = train, \n",
    "                   linewidth=4)\n",
    "\n",
    "## Fixing title, xlabel and ylabel\n",
    "plt.title(\"Severity of illness of each reaces\", fontsize = 20, fontweight = 'bold', pad=40)\n",
    "plt.xlabel(\"Race\", fontsize = 20, fontweight = 'bold');\n",
    "plt.ylabel(\"Number of Patient\", fontsize = 20, fontweight = 'bold')\n",
    "\n",
    "## Fixing legends\n",
    "leg = ax.get_legend()\n",
    "leg.set_title(\"Severity of illness\")\n",
    "legs = leg.texts\n",
    "plt.show()\n",
    "plt.rcParams['figure.figsize'] = [20, 15]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a145d75a",
   "metadata": {},
   "source": [
    "### ---------> OBSERVATION\n",
    "***\n",
    "According to this bar chart, the white people have the highest number of people who have the severity of illness from 2 to 3. That can be the reasons why they stay in the hospital more than 3 days in the hospital."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62aac14",
   "metadata": {},
   "source": [
    "<a id=\"3.2.7\"></a>\n",
    "## 3.2.7 Medical Cost of each Race in both group stay more vs less than 3 days in Hospital\n",
    "****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6716baec",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"darkgrid\")\n",
    "\n",
    "plot = sns.catplot(data=train, kind=\"bar\", x=\"LengthOfStay\", y=\"AverageCostInCounty\",  hue=\"Race\", height = 10)\n",
    "plot.set_xticklabels(['More than 3 days', 'Less than 3 days'])\n",
    "\n",
    "plot.fig.suptitle(\"Medical Cost of each Race in both group stay more vs less than 3 days in Hospital\", fontsize=25, y=1.08, fontweight = 'bold')\n",
    "plot.set_xlabels(\"Length Of Stay\", fontsize = 20, fontweight = 'bold' )\n",
    "plot.set_ylabels(\"Medical Cost\", fontsize = 20, fontweight = 'bold')\n",
    "plt.rcParams['figure.figsize'] = [20, 15]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b94f1d2",
   "metadata": {},
   "source": [
    "### ---------> OBSERVATION\n",
    "***\n",
    "This bar plot displays medical cost of each race in both group stay more vs less than 3 days in hospital. Overall, same as we expected, it may be because the Black/African American people have to pay more medical cost in either stay more or less than 3 days option. However, it is still interesting that the white people have more extreme illness but they still pay the lowest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d94062",
   "metadata": {},
   "source": [
    "<a id=\"3.2.8\"></a>\n",
    "## 3.2.8 Medical Cost of each Severity of illness in both group stay more vs less than 3 days in Hospital\n",
    "****\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075fcb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"darkgrid\")\n",
    "\n",
    "plot = sns.catplot(data=train, kind=\"bar\", x=\"APRSeverityOfIllnessCode\", y=\"AverageCostInCounty\",  hue=\"LengthOfStay\", height = 10)\n",
    "\n",
    "plot.fig.suptitle(\"Medical Cost of each Severity of illness in both group stay more vs less than 3 days in Hospital\", fontsize=25, y=1.08, fontweight = 'bold')\n",
    "plot.set_xlabels(\"Severity of illness\", fontsize = 20, fontweight = 'bold' )\n",
    "plot.set_ylabels(\"Medical Cost\", fontsize = 20, fontweight = 'bold')\n",
    "plt.rcParams['figure.figsize'] = [20, 15]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45c2cda",
   "metadata": {},
   "source": [
    "### ---------> OBSERVATION\n",
    "***\n",
    "This bar chart is utilised for comparing the magnitude of the medical cost of 2 options which are stay more than 3 days and stay less than 3 days in 4 different of illness. Overall, suprisingly, the group of people who have the most extreme illness pay the lowest cost, while the moderate and the major pay the highest amount of money."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51212670",
   "metadata": {},
   "source": [
    "<a id=\"3.2.9\"></a>\n",
    "## 3.2.9 Average hospitalization Cost Distribution Stay more vs less than 3 days\n",
    "****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bbc84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kernel Density Plot\n",
    "fig = plt.figure(figsize=(15,8),)\n",
    "ax=sns.kdeplot(train.loc[(train['LengthOfStay'] == 0),'AverageCostInCounty'] , color='gray',shade=True)\n",
    "ax=sns.kdeplot(train.loc[(train['LengthOfStay'] == 1),'AverageCostInCounty'] , color='g',shade=True)\n",
    "plt.title('Average hospitalization Cost Distribution Stay more vs less than 3 days', fontsize = 25, pad = 40)\n",
    "plt.ylabel(\"Frequency of Passenger\", fontsize = 15, labelpad = 20)\n",
    "plt.xlabel(\"Medical cost\", fontsize = 15, labelpad = 20);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4e8dd1",
   "metadata": {},
   "source": [
    "### ---------> OBSERVATION\n",
    "***\n",
    "This graph demonstrates the Average Hospitality Cost of both groups which are stay more or less than 3 days. Most of people have to pay around 3000 to 3500 for their medical cost for both group stay more and less than 3 days. Suprisingly, most of the people who stay less than 3 days in hospital have to pay a slightly higher medical cost."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0237b4a5",
   "metadata": {},
   "source": [
    "<a id=\"3.2.10\"></a>\n",
    "## 3.2.10 Birth Weight Distribution - Stay more vs less than 3 days\n",
    "****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0471bf0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Kernel Density Plot\n",
    "fig = plt.figure(figsize=(15,8),)\n",
    "ax=sns.kdeplot(train.loc[(train['LengthOfStay'] == 0),'BirthWeight'] , color='gray',shade=True)\n",
    "ax=sns.kdeplot(train.loc[(train['LengthOfStay'] == 1),'BirthWeight'] , color='g',shade=True)\n",
    "plt.title('Birth Weight Distribution - Stay more vs less than 3 days', fontsize = 25, pad = 40)\n",
    "plt.ylabel(\"Frequency of Passenger\", fontsize = 15, labelpad = 20)\n",
    "plt.xlabel(\"Birth Weight (g)\", fontsize = 15, labelpad = 20);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebe05d6",
   "metadata": {},
   "source": [
    "### ---------> OBSERVATION\n",
    "***\n",
    "According to graph, most of the newborn have the birth weigth around from 3000 to 4000 gram. Moreover, most of the newborn having the birth weigth from 3000 to 4000 gram stay in the hospital less than 3 days. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97482c11",
   "metadata": {},
   "source": [
    "<a id=\"3.2.11\"></a>\n",
    "## 3.2.11 Average Charges In County Distribution - Stay more vs less than 3 days\n",
    "****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75d1ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kernel Density Plot\n",
    "fig = plt.figure(figsize=(15,8),)\n",
    "ax=sns.kdeplot(train.loc[(train['LengthOfStay'] == 0),'AverageChargesInCounty'] , color='gray',shade=True)\n",
    "ax=sns.kdeplot(train.loc[(train['LengthOfStay'] == 1),'AverageChargesInCounty'] , color='g',shade=True)\n",
    "plt.title('Average Charges In County Distribution - Stay more vs less than 3 days', fontsize = 25, pad = 40)\n",
    "plt.ylabel(\"Frequency of Passenger\", fontsize = 15, labelpad = 20)\n",
    "plt.xlabel(\"Average Charges In County\", fontsize = 15, labelpad = 20);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f071cb83",
   "metadata": {},
   "source": [
    "### ---------> OBSERVATION\n",
    "***\n",
    "This plot can be divided into 2 part which are from 0 to 6000 and 8000 to 12000. Overall, most of the people who stay more than 3 days in hospital are from the counties which have the higher average medical charges. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6341782a",
   "metadata": {},
   "source": [
    "<a id=\"3.2.12\"></a>\n",
    "## 3.2.12 Average Cost In Facility Distribution - Stay more vs less than 3 days\n",
    "****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7339f972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kernel Density Plot\n",
    "fig = plt.figure(figsize=(15,8),)\n",
    "ax=sns.kdeplot(train.loc[(train['LengthOfStay'] == 0),'AverageCostInFacility'] , color='gray',shade=True,label='not survived')\n",
    "ax=sns.kdeplot(train.loc[(train['LengthOfStay'] == 1),'AverageCostInFacility'] , color='g',shade=True, label='survived')\n",
    "plt.title('Average Cost In Facility Distribution - Stay more vs less than 3 days', fontsize = 25, pad = 40)\n",
    "plt.ylabel(\"Frequency of Passenger\", fontsize = 15, labelpad = 20)\n",
    "plt.xlabel(\"Average Cost In Facility\", fontsize = 15, labelpad = 20);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75776685",
   "metadata": {},
   "source": [
    "### ---------> OBSERVATION\n",
    "***\n",
    "This plot demonstrates the average charges in facility. Overall, the people who do not stay in the hospital more than 3 days but still have to pay higher cost in facility than the people who stay more than 3 days in the hospital."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ea6825",
   "metadata": {},
   "source": [
    "<a id=\"3.2.13\"></a>\n",
    "## 3.2.13 Average Charges In Facility Distribution - Stay more vs less than 3 days\n",
    "****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634ccd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kernel Density Plot\n",
    "fig = plt.figure(figsize=(15,8),)\n",
    "ax=sns.kdeplot(train.loc[(train['LengthOfStay'] == 0),'AverageChargesInFacility'] , color='gray',shade=True,label='not survived')\n",
    "ax=sns.kdeplot(train.loc[(train['LengthOfStay'] == 1),'AverageChargesInFacility'] , color='g',shade=True, label='survived')\n",
    "plt.title('Average Charges In Facility Distribution - Stay more vs less than 3 days', fontsize = 25, pad = 40)\n",
    "plt.ylabel(\"Frequency of Passenger\", fontsize = 15, labelpad = 20)\n",
    "plt.xlabel(\"Average Charges In Facility\", fontsize = 15, labelpad = 20);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e21d300",
   "metadata": {},
   "source": [
    "<a id=\"3.2.14\"></a>\n",
    "## 3.2.14 Factorplot of Average Charges In Facility Length Of Stay\n",
    "****\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0b2fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.factorplot(x =  \"TypeOfAdmission\", y = \"LengthOfStay\", data = train,kind = \"point\",size = 8)\n",
    "plt.title('Factorplot of Average Charges In Facility Length Of Stay', fontsize = 25)\n",
    "plt.subplots_adjust(top=0.85)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3383e2bd",
   "metadata": {},
   "source": [
    "### ---------> OBSERVATION\n",
    "***\n",
    "From this plot, the Newborn and the Urgent people have the tendency to stay more than 3 days in the hospital"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7b6111",
   "metadata": {},
   "source": [
    "<a id=\"3.3\"></a>\n",
    "# 3.3 Summary\n",
    "****\n",
    "> - Most of people stay less than 3 days in the hospital.\n",
    "> - Most of people who have the minor illness tend to stay less than 3 days in the hospital\n",
    "> - People have the extreme illness have the tendency to stay more than 3 days in the hospital.\n",
    "> - People who stay more than 3 days in the hospital have to pay the higher medical cost.\n",
    "> - The number of Female vs Male patient is approximately equal.\n",
    "> - The number of patient who have the extreme illness is lower than those people have the minor illness.\n",
    "> - The number of white people is higher than the number of people who are Black/African American and multi-racial. Moreover, those white people"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c554e1c9",
   "metadata": {},
   "source": [
    "<a id=\"4\"></a>\n",
    "<h1 style=\"color:#ffc0cb;font-size:40px;font-family:Georgia;text-align:center;\"><strong> üìä 4. Statistical Overview</strong></h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268c450b",
   "metadata": {},
   "source": [
    "<a id=\"4.1\"></a>\n",
    "# 4.1 Descriptive statistics for Variability\n",
    "****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4388984b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e82026",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe(include =['O'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a76a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "survived_summary = train.groupby(\"Gender\")\n",
    "survived_summary.mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef6f8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "survived_summary = train.groupby(\"APRSeverityOfIllnessCode\")\n",
    "survived_summary.mean().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45acf5fd",
   "metadata": {},
   "source": [
    "### ---------> OBSERVATION\n",
    "***\n",
    "- This train data set has 891 raw and 9 columns. \n",
    "- Only 17% people stay more than 3 days in the hospital.\n",
    "- Only 16% female and 18% male stay more than 3 days in the hospital.\n",
    "- Only 12% people having the minor illness and 26% people having the moderate illness stays more than 3 days in the hospital, meanwhile, more than half of the people having major and 100% people having the extreme illness stay more than 3 days in the hospital"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4eef28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placing 0 for female and \n",
    "# 1 for male in the \"Sex\" column. \n",
    "train['Gender'] = train.Gender.apply(lambda x: 0 if x == \"FEMALE\" else 1)\n",
    "test['Gender'] = test.Gender.apply(lambda x: 0 if x == \"FEMALE\" else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a29c225",
   "metadata": {},
   "source": [
    "<a id=\"4.2\"></a>\n",
    "# 4.2 Correlation Matrix and Heatmap\n",
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6159611f",
   "metadata": {},
   "source": [
    "<a id=\"4.2.1\"></a>\n",
    "## 4.2.1 Correlation Matrix\n",
    "****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301ea0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(abs(train.corr()['LengthOfStay']).sort_values(ascending = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b83370",
   "metadata": {},
   "source": [
    "### ---------> OBSERVATION\n",
    "***\n",
    "**`APRSeverityOfIllnessCode` is the most important correlated feature with *`LengthOfStay`(dependent variable)* feature followed by Pclass.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b919d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get the most important variables. \n",
    "corr = train.corr()**2\n",
    "corr.LengthOfStay.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a8439e",
   "metadata": {},
   "source": [
    "**Squaring the correlation feature not only gives on positive correlations but also amplifies the relationships.** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954fea8a",
   "metadata": {},
   "source": [
    "<a id=\"4.2.2\"></a>\n",
    "## 4.2.2 Heat map\n",
    "****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee5d618",
   "metadata": {},
   "outputs": [],
   "source": [
    "## heatmeap to see the correlation between features. \n",
    "# Generate a mask for the upper triangle (taken from seaborn example gallery)\n",
    "import numpy as np\n",
    "mask = np.zeros_like(train.corr(), dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "sns.set_style('whitegrid')\n",
    "plt.subplots(figsize = (15,12))\n",
    "sns.heatmap(train.corr(), \n",
    "            annot=True,\n",
    "            mask = mask,\n",
    "            cmap = 'RdBu', ## in order to reverse the bar replace \"RdBu\" with \"RdBu_r\"\n",
    "            linewidths=.9, \n",
    "            linecolor='white',\n",
    "            fmt='.2g',\n",
    "            center = 0,\n",
    "            square=True)\n",
    "plt.title(\"Correlations Among Features\", y = 1.03,fontsize = 20, pad = 40);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61aea7d0",
   "metadata": {},
   "source": [
    "### ---------> OBSERVATION\n",
    "***\n",
    "#### Positive Correlation Features:\n",
    "- Gender and LengthOfStay: 0.029\n",
    "- CCSProcedureCode and LengthOfStay: 0.035\n",
    "- APRSeverityOfIllnessCode and LengthOfStay: 0.27\n",
    "- AverageCostInCounty and LengthOfStay: 0.058\n",
    "\n",
    "\n",
    "#### Negative Correlation Features:\n",
    "- BirthWeight and LengthOfStay: -0.029"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c140a5",
   "metadata": {},
   "source": [
    "<a id=\"4.3\"></a>\n",
    "# 4.3 Statistical Test for Correlation\n",
    "****\n",
    "> **Null Hypothesis($H_0$):**  male mean is greater or equal to female mean.  \n",
    ">  **Alternative Hypothesis($H_A$):** male mean is less than female mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a18907",
   "metadata": {},
   "outputs": [],
   "source": [
    "male_mean = train[train['Gender'] == 1].LengthOfStay.mean()\n",
    "\n",
    "female_mean = train[train['Gender'] == 0].LengthOfStay.mean()\n",
    "print (\"Male LengthOfStay mean: \" + str(male_mean))\n",
    "print (\"female LengthOfStay mean: \" + str(female_mean))\n",
    "\n",
    "print (\"The mean difference between male and female LengthOfStay: \" + str(male_mean - female_mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1709947d",
   "metadata": {},
   "source": [
    "### ---------> OBSERVATION\n",
    "***\n",
    "Not accept Null Hypothesis ($H_0$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5521edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separating male and female dataframe. \n",
    "import random\n",
    "male = train[train['Gender'] == 1]\n",
    "female = train[train['Gender'] == 0]\n",
    "\n",
    "## empty list for storing mean sample\n",
    "m_mean_samples = []\n",
    "f_mean_samples = []\n",
    "\n",
    "for i in range(50):\n",
    "    m_mean_samples.append(np.mean(random.sample(list(male['LengthOfStay']),50,)))\n",
    "    f_mean_samples.append(np.mean(random.sample(list(female['LengthOfStay']),50,)))\n",
    "    \n",
    "\n",
    "# Print them out\n",
    "print (f\"Male mean sample mean: {round(np.mean(m_mean_samples),2)}\")\n",
    "print (f\"Male mean sample mean: {round(np.mean(f_mean_samples),2)}\")\n",
    "print (f\"Difference between male and female mean sample mean: {round(np.mean(m_mean_samples) - np.mean(f_mean_samples),2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0198a378",
   "metadata": {},
   "source": [
    "H0: male mean is greater or equal to female mean<br>\n",
    "H1: male mean is less than female mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f39432e",
   "metadata": {},
   "source": [
    "According to the samples our male samples ($\\bar{x}_m$) and female samples($\\bar{x}_f$) mean measured difference is ~ 0.55(statistically this is called the point estimate of the male population mean and female population mean). keeping in mind that...\n",
    "* We randomly select 50 people to be in the male group and 50 people to be in the female group. \n",
    "* We know our sample is selected from a broader population(trainning set). \n",
    "* We know we could have totally ended up with a different random sample of males and females.\n",
    "***\n",
    "With all three points above in mind, how confident are we that, the measured difference is real or statistically significant? we can perform a **t-test** to evaluate that. When we perform a **t-test** we are usually trying to find out **an evidence of significant difference between population mean with hypothesized mean(1 sample t-test) or in our case difference between two population means(2 sample t-test).** \n",
    "\n",
    "\n",
    "\n",
    "The **t-statistics** is the measure of a degree to which our groups differ standardized by the variance of our measurements. In order words, it is basically the measure of signal over noise. Let us describe the previous sentence a bit more for clarification. I am going to use [this post](http://blog.minitab.com/blog/statistics-and-quality-data-analysis/what-is-a-t-test-and-why-is-it-like-telling-a-kid-to-clean-up-that-mess-in-the-kitchen) as reference to describe the t-statistics here. \n",
    "\n",
    "\n",
    "#### Calculating the t-statistics\n",
    "# $$t = \\frac{\\bar{x}-\\mu}{\\frac{S} {\\sqrt{n}} }$$\n",
    "\n",
    "Here..\n",
    "* $\\bar{x}$ is the sample mean. \n",
    "* $\\mu$ is the hypothesized mean. \n",
    "* S is the standard deviation. \n",
    "* n is the sample size. \n",
    "\n",
    "\n",
    "1. Now, the denominator of this fraction $(\\bar{x}-\\mu)$ is basically the strength of the signal. where we calculate the difference between hypothesized mean and sample mean. If the mean difference is higher, then the signal is stronger. \n",
    "\n",
    "the numerator of this fraction ** ${S}/ {\\sqrt{n}}$ ** calculates the amount of variation or noise of the data set. Here S is standard deviation, which tells us how much variation is there in the data. n is the sample size. \n",
    "\n",
    "So, according to the explanation above, the t-value or t-statistics is basically measures the strength of the signal(the difference) to the amount of noise(the variation) in the data and that is how we calculate the t-value in one sample t-test. However, in order to calculate between two sample population mean or in our case we will use the follow equation. \n",
    "\n",
    "# $$t = \\frac{\\bar{x}_M - \\bar{x}_F}{\\sqrt {s^2 (\\frac{1}{n_M} + \\frac{1}{n_F})}}$$\n",
    "\n",
    "This equation may seem too complex, however, the idea behind these two are similar. Both of them have the concept of signal/noise. The only difference is that we replace our hypothesis mean with another sample mean and the two sample sizes repalce one sample size. \n",
    "\n",
    "Here..\n",
    "* $\\bar{x}_M$ is the mean of our male group sample measurements. \n",
    "* $ \\bar{x}_F$ is the mean of female group samples. \n",
    "* $ n_M$ and $n_F$ are the sample number of observations in each group. \n",
    "* $ S^2$ is the sample variance.\n",
    "\n",
    "It is good to have an understanding of what going on in the background. However, we will use **scipy.stats** to find the t-statistics. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc6ac59",
   "metadata": {},
   "source": [
    "<a id=\"5\"></a>\n",
    "<h1 style=\"color:#ffc0cb;font-size:40px;font-family:Georgia;text-align:center;\"><strong> üõ† 5. Feature Engineering</strong></h1>\n",
    "\n",
    "Feature Engineering is exactly what its sounds like. Sometimes we want to create extra features from with in the features that we have, sometimes we want to remove features that are alike. Features engineering is the simple word for doing all those. It is important to remember that we will create new features in such ways that will not cause **multicollinearity(when there is a relationship among independent variables)** to occur. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fc49f1",
   "metadata": {},
   "source": [
    "<a id=\"5.1\"></a>\n",
    "# 5.1 Encoding\n",
    "****\n",
    "Encode categorical data into digits to fit and evaluate model.\n",
    "\n",
    "#### Few reasons why categorical values can be difficult to deal with are:\n",
    "\n",
    "- High cardinality (Features with a large number of levels)\n",
    "- Algebraic Machine Learning models, whose input must be numerical. (Hence categorical must be transformed into numbers before applying a learning algorithm to them)\n",
    "- It is difficult for an ML model to differentiate between highly different levels.\n",
    "\n",
    "In this report, there are 2 main approaches which are onehot encoding, find and replace  will be applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18088a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['EmergencyDepartmentIndicator'] = np.where(train.EmergencyDepartmentIndicator == 'Y', 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e262de31",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder=ce.OneHotEncoder(cols=['Race', 'TypeOfAdmission', 'PaymentTypology'],handle_unknown='return_nan',return_df=True,use_cat_names=True)\n",
    "#Fit and transform Data\n",
    "train = encoder.fit_transform(train)\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cec3e64",
   "metadata": {},
   "source": [
    "<a id=\"5.2\"></a>\n",
    "# 5.2 Separating dependent and independent variables\n",
    "****\n",
    "Before we apply any machine learning models, It is important to separate dependent and independent variables. Our dependent variable or target variable is something that we are trying to find, and our independent variable is the features we use to find the dependent variable. The way we use machine learning algorithm in a dataset is that we train our machine learning model by specifying independent variables and dependent variable. To specify them, we need to separate them from each other, and the code below does just that.\n",
    "\n",
    "P.S. In our test dataset, we do not have a dependent variable feature. We are to predict that using machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0c3245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separating our independent and dependent variable\n",
    "X = train.drop(['LengthOfStay'], axis = 1)\n",
    "y = train[\"LengthOfStay\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68a5b9b",
   "metadata": {},
   "source": [
    "<a id=\"5.3\"></a>\n",
    "# 5.3 Splitting the training data\n",
    "***\n",
    "There are multiple ways of splitting data. They are...\n",
    "* train_test_split.\n",
    "* cross_validation. \n",
    "\n",
    "We have separated dependent and independent features; We have separated train and test data. So, why do we still have to split our training data? If you are curious about that, I have the answer. For this competition, when we train the machine learning algorithms, we use part of the training set usually two-thirds of the train data. Once we train our algorithm using 2/3 of the train data, we start to test our algorithms using the remaining data. If the model performs well we dump our test data in the algorithms to predict and submit the competition. The code below, basically splits the train data into 4 parts, **X_train**, **X_test**, **y_train**, **y_test**.  \n",
    "* **X_train** and **y_train** first used to train the algorithm. \n",
    "* then, **X_test** is used in that trained algorithms to predict **outcomes. **\n",
    "* Once we get the **outcomes**, we compare it with **y_test**\n",
    "\n",
    "By comparing the **outcome** of the model with **y_test**, we can determine whether our algorithms are performing well or not. As we compare we use confusion matrix to determine different aspects of model performance.\n",
    "\n",
    "P.S. When we use cross validation it is important to remember not to use **X_train, X_test, y_train and y_test**, rather we will use **X and y**. I will discuss more on that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39720405",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size = .30, random_state=42)\n",
    "\n",
    "print(\"Length of X_train: \" + str(len(X_train)))\n",
    "print(\"Length of X_test: \" + str(len(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13a9392",
   "metadata": {},
   "source": [
    "<a id=\"5.4\"></a>\n",
    "# 5.4 Feature Scaling\n",
    "***\n",
    "Feature scaling is an important concept of machine learning models. Often times a dataset contain features highly varying in magnitude and unit. For some machine learning models, it is not a problem. However, for many other ones, its quite a problem. Many machine learning algorithms uses euclidian distances to calculate the distance between two points, it is quite a problem. Let's again look at a the sample of the **train** dataset below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c00859",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1b4e06",
   "metadata": {},
   "source": [
    "### ---------> OBSERVATION\n",
    "***\n",
    "Here `CCSProcedureCode`, `BirthWeight`, `AverageCostInCounty`, `AverageChargesInCounty`, `AverageCostInFacility`, `AverageChargesInFacility` is much higher in magnitude compared to others machine learning features. This can create problems as many machine learning models will get confused thinking they have higher weight than other features. Therefore, we need to do feature scaling to get a better result. \n",
    "There are multiple ways to do feature scaling. \n",
    "<ul>\n",
    "    <li><b>MinMaxScaler</b>-Scales the data using the max and min values so that it fits between 0 and 1.</li>\n",
    "    <li><b>StandardScaler</b>-Scales the data so that it has mean 0 and variance of 1.</li>\n",
    "    <li><b>RobustScaler</b>-Scales the data similary to Standard Scaler, but makes use of the median and scales using the interquertile range so as to aviod issues with large outliers.</b>\n",
    " </ul>\n",
    "I will discuss more on that in a different kernel. For now we will use <b>Standard Scaler</b> to feature scale our dataset. \n",
    "\n",
    "P.S. I am showing a sample of both before and after so that you can see how scaling changes the dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b88c7b",
   "metadata": {},
   "source": [
    "<h1><font color=\"$5831bc\" face=\"Comic Sans MS\">Before Scaling</font></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11409f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = X_train.columns \n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d396ed",
   "metadata": {},
   "source": [
    "<h1><font color=\"$5831bc\" face=\"Comic Sans MS\">Scaling</font></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382515dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "## We will be using standardscaler to transform\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "st_scale = StandardScaler()\n",
    "\n",
    "## transforming \"train_x\"\n",
    "X_train = st_scale.fit_transform(X_train)\n",
    "## transforming \"test_x\"\n",
    "X_test = st_scale.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e0f2ab",
   "metadata": {},
   "source": [
    "<h1><font color=\"#5831bc\" face=\"Comic Sans MS\">After Scaling</font></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419782a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(X_train, columns=headers).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84349d6a",
   "metadata": {},
   "source": [
    "<a id=\"6\"></a>\n",
    "<h1 style=\"color:#ffc0cb;font-size:40px;font-family:Georgia;text-align:center;\"><strong> ü§ñ 6. Model training</strong></h1>\n",
    "\n",
    "### Reproducibility: Setting the seed\n",
    "\n",
    "With the aim to ensure reproducibility between runs of the same notebook, but also between the research and production environment, for each step that includes some element of randomness, it is extremely important that we **set the seed to 42**.\n",
    "\n",
    "\n",
    "### Evaluation metric:\n",
    "Since this is a multi-class problem, I use confusion matrix to calculate a variety of metrics\n",
    "\n",
    "\n",
    "<a id=\"5.1\"></a>\n",
    "# Train/Test split\n",
    "Separating the data into train and test involves randomness."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0bb9c9b",
   "metadata": {},
   "source": [
    "<a id=\"6.1\"></a>\n",
    "# 6.1 Logistic Regression\n",
    "****\n",
    "<img src=\"https://www.machinelearningplus.com/wp-content/uploads/2017/09/linear_vs_logistic_regression.jpg\" class=\"center\" width=\"600\" >\n",
    "<h4 align=\"right\">Source: Machine Learning Plus</h4>\n",
    "\n",
    "**Logistic Regression**. Logistic regression is a famous classifier still used today frequently despite its age. It is a regression similar to **Linear regression**, yet operates as a classifier. To understand logistic regression, we should have some idea about linear regression. Let's have a look at it. \n",
    "\n",
    "Hopefully, we all know that any linear equation can be written in the form of...\n",
    "\n",
    "# $$ {y} = mX + b $$\n",
    "\n",
    "* Here, m = slope of the regression line. it represents the relationship between X and y. \n",
    "* b = y-intercept. \n",
    "* x and y are the points location in x_axis and y_axis respectively. \n",
    "<br/>\n",
    "\n",
    "If you want to know how, check out this [video](https://www.khanacademy.org/math/algebra/two-var-linear-equations/writing-slope-intercept-equations/v/graphs-using-slope-intercept-form). So, this slope equation can also be written as...\n",
    "\n",
    "## $$ y = \\beta_0 + \\beta_1 x + \\epsilon \\\\ $$\n",
    "\n",
    "This is the equation for a simple linear regression.\n",
    "here,\n",
    "* y = Dependent variable. \n",
    "* $\\beta_0$ = the intercept, it is constant. \n",
    "* $\\beta_1$ = Coefficient of independent variable. \n",
    "* $x$ = Indepentent variable. \n",
    "* $ \\epsilon$ = error or residual. \n",
    "\n",
    "\n",
    "We use this function to predict the value of a dependent variable with the help of only one independent variable. Therefore this regression is called **Simple Linear Regression.** \n",
    "\n",
    "Similar to **Simple Linear Regression**, there is **Multiple Linear Regression** which can be used to predict dependent variable using multiple independent variables. Let's look at the equation for **Multiple Linear Regression**, \n",
    "\n",
    "## $$ \\hat{y} = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + ... + \\beta_n x_n $$\n",
    "\n",
    "\n",
    "If you would like to know more about **Linear Regression** checkout this [kernel](https://www.kaggle.com/masumrumi/a-stats-analysis-and-ml-workflow-of-house-pricing). \n",
    "\n",
    "So, we know/reviewed a bit about linear regression, and therefore we know how to deal with data that looks like this, \n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/3/3a/Linear_regression.svg/1200px-Linear_regression.svg.png\" width=\"600\">\n",
    "\n",
    "Here the data point's in this graph is continuous and therefore the problem is a regression one. However, what if we have data that when plotted in a scatter graph, looks like this...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5468c995",
   "metadata": {},
   "source": [
    "<a id=\"6.1.1\"></a>\n",
    "## 6.1.1 Simple Logistic Regression as a Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f8516e",
   "metadata": {},
   "source": [
    "<a id=\"6.1.1.a\"></a>\n",
    "## 6.1.1.a Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e43e2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression(fit_intercept = False, C = 1e12, solver='lbfgs', multi_class='auto')\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123f427f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "y_hat_test = logreg.predict(X_test)\n",
    "y_hat_train = logreg.predict(X_train)\n",
    "\n",
    "y_hat_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f08b6d8",
   "metadata": {},
   "source": [
    "<a id=\"6.1.1.b\"></a>\n",
    "## 6.1.1.b Evaluating a classification model\n",
    "***\n",
    "There are multiple ways to evaluate a classification model. \n",
    "\n",
    "* Confusion Matrix. \n",
    "* ROC Curve\n",
    "* AUC Curve. \n",
    "\n",
    "\n",
    "## Confusion Matrix\n",
    "<b>Confusion matrix</b>, a table that <b>describes the performance of a classification model</b>. Confusion Matrix tells us how many our model predicted correctly and incorrectly in terms of binary/multiple outcome classes by comparing actual and predicted cases. For example, in terms of this dataset, our model is a binary one and we are trying to classify whether the passenger survived or not survived. we have fit the model using **X_train** and **y_train** and predicted the outcome of **X_test** in the variable **y_pred**. So, now we will use a confusion matrix to compare between **y_test** and **y_pred**. Let's do the confusion matrix.  \n",
    "\n",
    "A confusion matrix contains:\n",
    "\n",
    "<ul style=\"list-style-type:square;\">\n",
    "    <li><b>True Positive(TP)</b>: values that the model predicted as yes(survived) and is actually yes(survived).</li>\n",
    "    <li><b>True Negative(TN)</b>: values that model predicted as no(not-survived) and is actually no(not-survived)</li>\n",
    "    <li><b>False Positive(or Type I error)</b>: values that model predicted as yes(survived) but actually no(not-survived)</li>\n",
    "    <li><b>False Negative(or Type II error)</b>: values that model predicted as no(not-survived) but actually yes(survived)</li>\n",
    "</ul>\n",
    "\n",
    "**Misclassification Rate:** Misclassification Rate is the measure of how often the model is wrong**\n",
    "* Misclassification Rate and Accuracy are opposite of each other.\n",
    "* Missclassification is equivalent to 1 minus Accuracy. \n",
    "* Misclassification Rate is also known as \"Error Rate\".\n",
    "\n",
    "> (FP + FN)/Total = (28+30)/294 = 0.19\n",
    "\n",
    "**True Positive Rate/Recall/Sensitivity:** How often the model predicts yes(survived) when it's actually yes(survived)?\n",
    "> TP/(TP+FN) = 87/(87+30) = 0.7435897435897436\n",
    "\n",
    "\n",
    "**False Positive Rate:** How often the model predicts yes(survived) when it's actually no(not-survived)?\n",
    "> FP/(FP+TN) = 28/(28+149) = 0.15819209039548024\n",
    "\n",
    "**True Negative Rate/Specificity:** How often the model predicts no(not-survived) when it's actually no(not-survived)?\n",
    "* True Negative Rate is equivalent to 1 minus False Positive Rate.\n",
    "\n",
    "> TN/(TN+FP) = 149/(149+28) = 0.8418079096045198\n",
    "\n",
    "**Precision:** How often is it correct when the model predicts yes. \n",
    "> TP/(TP+FP) = 87/(87+28) = 0.7565217391304347"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d32d91",
   "metadata": {},
   "source": [
    "### Precision score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8b07b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train_preds = logreg.predict(X_train)\n",
    "test_preds = logreg.predict(X_test)\n",
    "\n",
    "print(classification_report(y_train, train_preds))\n",
    "print(classification_report(y_test, test_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f7b8ae",
   "metadata": {},
   "source": [
    "### Plot the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29489bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax0, ax1) = plt.subplots(1, 2, figsize=(20, 8))\n",
    "plot_confusion_matrix(logreg, X_train, y_train, ax=ax0)\n",
    "plot_confusion_matrix(logreg, X_test, y_test, ax=ax1)\n",
    "ax0.title.set_text('Train Confusion Matrix')\n",
    "ax1.title.set_text('Test Confusion Matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8c21d6",
   "metadata": {},
   "source": [
    "### AUC & ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb3e15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = y_train == y_hat_train\n",
    "\n",
    "print('Number of values correctly predicted:')\n",
    "print(pd.Series(residuals).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cb35b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = y_test == y_hat_test\n",
    "\n",
    "print('Number of values correctly predicted: ')\n",
    "print(pd.Series(residuals).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7725d026",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "#plt.style.use('seaborn-pastel')\n",
    "y_score = logreg.decision_function(X_test)\n",
    "\n",
    "FPR, TPR, _ = roc_curve(y_test, y_score)\n",
    "ROC_AUC = auc(FPR, TPR)\n",
    "print (ROC_AUC)\n",
    "\n",
    "plt.figure(figsize =[11,9])\n",
    "plt.plot(FPR, TPR, label= 'ROC curve(area = %0.2f)'%ROC_AUC, linewidth= 4)\n",
    "plt.plot([0,1],[0,1], 'k--', linewidth = 4)\n",
    "plt.xlim([0.0,1.0])\n",
    "plt.ylim([0.0,1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize = 18)\n",
    "plt.ylabel('True Positive Rate', fontsize = 18)\n",
    "plt.title('ROC for Hospital Length of Stay', fontsize= 18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4afd50da",
   "metadata": {},
   "source": [
    "### Plot PR curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4f8ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "y_score = logreg.decision_function(X_test)\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_score)\n",
    "PR_AUC = auc(recall, precision)\n",
    "\n",
    "plt.figure(figsize=[11,9])\n",
    "plt.plot(recall, precision, label='PR curve (area = %0.2f)' % PR_AUC, linewidth=4)\n",
    "plt.xlabel('Recall', fontsize=18)\n",
    "plt.ylabel('Precision', fontsize=18)\n",
    "plt.title('Precision Recall Curve for Hospital Length of Stay', fontsize=18)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01bc1e6a",
   "metadata": {},
   "source": [
    "### Using Cross-validation:\n",
    "Pros: \n",
    "* Helps reduce variance. \n",
    "* Expends models predictability. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b6e4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = st_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff358fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Using StratifiedShuffleSplit\n",
    "## We can use KFold, StratifiedShuffleSplit, StratiriedKFold or ShuffleSplit, They are all close cousins. look at sklearn userguide for more info.   \n",
    "from sklearn.model_selection import StratifiedShuffleSplit, cross_val_score\n",
    "cv = StratifiedShuffleSplit(n_splits = 10, test_size = .25, random_state = 0 ) # run model 10x with 60/30 split intentionally leaving out 10%\n",
    "## Using standard scale for the whole dataset.\n",
    "\n",
    "## saving the feature names for decision tree display\n",
    "column_names = X.columns\n",
    "\n",
    "X = sc.fit_transform(X)\n",
    "accuracies = cross_val_score(LogisticRegression(solver='liblinear'), X,y, cv  = cv)\n",
    "print (\"Cross-Validation accuracy scores:{}\".format(accuracies))\n",
    "print (\"Mean Cross-Validation accuracy score: {}\".format(round(accuracies.mean(),5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e5482a",
   "metadata": {},
   "source": [
    "<a id=\"6.1.2\"></a>\n",
    "# 6.1.2 Logistic Regression with GridSearch\n",
    "***\n",
    "* What is grid search? \n",
    "* What are the pros and cons?\n",
    "\n",
    "> **Gridsearch** is a simple concept but effective technique in Machine Learning. The word **GridSearch** stands for the fact that we are searching for optimal parameter/parameters over a \"grid.\" These optimal parameters are also known as **Hyperparameters**. **The Hyperparameters are model parameters that are set before fitting the model and determine the behavior of the model.**. For example, when we choose to use linear regression, we may decide to add a penalty to the loss function such as Ridge or Lasso. These penalties require specific alpha (the strength of the regularization technique) to set beforehand. The higher the value of alpha, the more penalty is being added. \n",
    "\n",
    ">**GridSearch finds the optimal value of alpha among a range of values provided** by us, and then we go on and use that optimal value to fit the model and get sweet results. It is essential to understand those model parameters are different from models outcomes, for example, **coefficients** or model evaluation metrics such as **accuracy score** or **mean squared error** are model outcomes and different than hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0baf6852",
   "metadata": {},
   "source": [
    "<a id=\"6.1.2.a\"></a>\n",
    "## 6.1.2.a Train Model\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54540e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "## C_vals is the alpla value of lasso and ridge regression(as alpha increases the model complexity decreases,)\n",
    "## remember effective alpha scores are 0<alpha<infinity \n",
    "C_vals = [0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1,2,3,4,5,6,7,8,9,10,12,13,14,15,16,16.5,17,17.5,18]\n",
    "## Choosing penalties(Lasso(l1) or Ridge(l2))\n",
    "penalties = ['l1','l2']\n",
    "## Choose a cross validation strategy. \n",
    "cv = StratifiedShuffleSplit(n_splits = 10, test_size = .25)\n",
    "\n",
    "## setting param for param_grid in GridSearchCV. \n",
    "param = {'penalty': penalties, 'C': C_vals}\n",
    "\n",
    "logreg = LogisticRegression(solver='liblinear')\n",
    "## Calling on GridSearchCV object. \n",
    "grid = GridSearchCV(estimator=LogisticRegression(), \n",
    "                           param_grid = param,\n",
    "                           scoring = 'accuracy',\n",
    "                            n_jobs =-1,\n",
    "                           cv = cv\n",
    "                          )\n",
    "## Fitting the model\n",
    "grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34051315",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Getting the best of everything. \n",
    "print (grid.best_score_)\n",
    "print (grid.best_params_)\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4cd4dfb",
   "metadata": {},
   "source": [
    "#### Using the best parameters from the grid-search. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf05edca",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Using the best parameters from the grid-search.\n",
    "logreg_grid = grid.best_estimator_\n",
    "logreg_grid.score(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894a54c5",
   "metadata": {},
   "source": [
    "<a id=\"6.1.2.a\"></a>\n",
    "## 6.1.2.b Evaluating a classification model\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d41fe28",
   "metadata": {},
   "source": [
    "Resources: \n",
    " * [Confusion Matrix](https://www.youtube.com/watch?v=8Oog7TXHvFY)\n",
    "### Under-fitting & Over-fitting: \n",
    "So, we have our first model and its score. But, how do we make sure that our model is performing well. Our model may be overfitting or underfitting. In fact, for those of you don't know what overfitting and underfitting is, Let's find out.\n",
    "\n",
    "![](https://cdncontribute.geeksforgeeks.org/wp-content/uploads/fittings.jpg)\n",
    "\n",
    "As you see in the chart above. **Underfitting** is when the model fails to capture important aspects of the data and therefore introduces more bias and performs poorly. On the other hand, **Overfitting** is when the model performs too well on the training data but does poorly in the validation set or test sets.  This situation is also known as having less bias but more variation and perform poorly as well. Ideally, we want to configure a model that performs well not only in the training data but also in the test data. This is where **bias-variance tradeoff** comes in. When we have a model that overfits, meaning less biased and more of variance, we introduce some bias in exchange of having much less variance. One particular tactic for this task is regularization models (Ridge, Lasso, Elastic Net).  These models are built to deal with the bias-variance tradeoff. This [kernel](https://www.kaggle.com/dansbecker/underfitting-and-overfitting) explains this topic well. Also, the following chart gives us a mental picture of where we want our models to be. \n",
    "![](http://scott.fortmann-roe.com/docs/docs/BiasVariance/biasvariance.png)\n",
    "\n",
    "Ideally, we want to pick a sweet spot where the model performs well in training set, validation set, and test set. As the model gets complex, bias decreases, variance increases. However, the most critical part is the error rates. We want our models to be at the bottom of that **U** shape where the error rate is the least. That sweet spot is also known as **Optimum Model Complexity(OMC).**\n",
    "\n",
    "Now that we know what we want in terms of under-fitting and over-fitting, let's talk about how to combat them. \n",
    "\n",
    "## ------>**How to combat over-fitting?**\n",
    "<ul>\n",
    "    <li>Simplify the model by using less parameters.</li>\n",
    "    <li>Simplify the model by changing the hyperparameters.</li>\n",
    "    <li>Introducing regularization models. </li>\n",
    "    <li>Use more training data. </li>\n",
    "    <li>Gatter more data ( and gather better quality data). </li>\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c878ec14",
   "metadata": {},
   "source": [
    "### Precision score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf55f610",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train_preds = grid.predict(X_train)\n",
    "test_preds = grid.predict(X_test)\n",
    "\n",
    "print(classification_report(y_train, train_preds))\n",
    "print(classification_report(y_test, test_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1718a016",
   "metadata": {},
   "source": [
    "### Plot the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9c536e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax0, ax1) = plt.subplots(1, 2, figsize=(20, 8))\n",
    "plot_confusion_matrix(grid, X_train, y_train, ax=ax0)\n",
    "plot_confusion_matrix(grid, X_test, y_test, ax=ax1)\n",
    "ax0.title.set_text('Train Confusion Matrix')\n",
    "ax1.title.set_text('Test Confusion Matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d59fcb",
   "metadata": {},
   "source": [
    "### Plot ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88ffc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "#plt.style.use('seaborn-pastel')\n",
    "y_score = grid.decision_function(X_test)\n",
    "\n",
    "FPR, TPR, _ = roc_curve(y_test, y_score)\n",
    "ROC_AUC = auc(FPR, TPR)\n",
    "print (ROC_AUC)\n",
    "\n",
    "plt.figure(figsize =[11,9])\n",
    "plt.plot(FPR, TPR, label= 'ROC curve(area = %0.2f)'%ROC_AUC, linewidth= 4)\n",
    "plt.plot([0,1],[0,1], 'k--', linewidth = 4)\n",
    "plt.xlim([0.0,1.0])\n",
    "plt.ylim([0.0,1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize = 18)\n",
    "plt.ylabel('True Positive Rate', fontsize = 18)\n",
    "plt.title('ROC for Hospital Length of Stay', fontsize= 18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f17458",
   "metadata": {},
   "source": [
    "### Plot PR curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e821008",
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = y_test == y_hat_test\n",
    "\n",
    "print('Number of values correctly predicted: ')\n",
    "print(pd.Series(residuals).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b922fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = y_train == y_hat_train\n",
    "\n",
    "print('Number of values correctly predicted:')\n",
    "print(pd.Series(residuals).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b869aa0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "y_score = grid.decision_function(X_test)\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_score)\n",
    "PR_AUC = auc(recall, precision)\n",
    "\n",
    "plt.figure(figsize=[11,9])\n",
    "plt.plot(recall, precision, label='PR curve (area = %0.2f)' % PR_AUC, linewidth=4)\n",
    "plt.xlabel('Recall', fontsize=18)\n",
    "plt.ylabel('Precision', fontsize=18)\n",
    "plt.title('Precision Recall Curve for Hospital Length of Stay', fontsize=18)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c2d79a",
   "metadata": {},
   "source": [
    "<a id=\"6.2\"></a>\n",
    "# 6.2 Random Forest\n",
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2bebaa",
   "metadata": {},
   "source": [
    "<a id=\"6.2.1\"></a>\n",
    "## 6.2.1 Random Forest with Pipelines\n",
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1751998e",
   "metadata": {},
   "source": [
    "<a id=\"6.2.1.a\"></a>\n",
    "## 6.2.1.a Train model\n",
    "****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920b35f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "pipeline = Pipeline([('ss', StandardScaler()),\n",
    "                     ('RF', RandomForestClassifier(random_state=42))])\n",
    "\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2608e8c9",
   "metadata": {},
   "source": [
    "<a id=\"6.2.1.b\"></a>\n",
    "## 6.2.1.b Evaluating a classification model\n",
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70032fc8",
   "metadata": {},
   "source": [
    "### Plot the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff93d4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "fig, (ax0, ax1) = plt.subplots(1, 2, figsize=(20, 8))\n",
    "plot_confusion_matrix(pipeline, X_train, y_train, ax=ax0)\n",
    "plot_confusion_matrix(pipeline, X_test, y_test, ax=ax1)\n",
    "ax0.title.set_text('Train Confusion Matrix')\n",
    "ax1.title.set_text('Test Confusion Matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0929506e",
   "metadata": {},
   "source": [
    "### Precision score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e9a509",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = pipeline.predict(X_train)\n",
    "test_preds = pipeline.predict(X_test)\n",
    "\n",
    "print(classification_report(y_train, train_preds))\n",
    "print(classification_report(y_test, test_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86a677e",
   "metadata": {},
   "source": [
    "<a id=\"6.2.2\"></a>\n",
    "## 6.2.2 Combining GridSearch+Random Forest with Pipelines\n",
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f71080b",
   "metadata": {},
   "source": [
    "<a id=\"6.2.2.a\"></a>\n",
    "## 6.2.2.a Train Model\n",
    "****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c326fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# defining pipeline + setting up grid for gridsearch w Random Forest\n",
    "pipeline2 = Pipeline([('ss', StandardScaler()), \n",
    "                              ('RF', RandomForestClassifier(random_state=42))])\n",
    "\n",
    "grid = [{'RF__max_depth': [4, 5], \n",
    "         'RF__min_samples_split': [5, 10], \n",
    "         'RF__min_samples_leaf': [3, 5]}]\n",
    "\n",
    "\n",
    "# perform gridsearch\n",
    "gridsearch = GridSearchCV(estimator=pipeline2, \n",
    "                          param_grid=grid, \n",
    "                          scoring='accuracy', \n",
    "                          cv=5)\n",
    "\n",
    "gridsearch.fit(X_train, y_train)\n",
    "test_preds = gridsearch.predict(X_test)\n",
    "\n",
    "\n",
    "gridsearch.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4942790",
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch.best_estimator_['RF'].feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59976d7",
   "metadata": {},
   "source": [
    "<a id=\"6.2.2.b\"></a>\n",
    "## 6.2.2.b Evaluating a classification model\n",
    "****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1689380",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "fig, (ax0, ax1) = plt.subplots(1, 2, figsize=(20, 8))\n",
    "plot_confusion_matrix(gridsearch, X_train, y_train, ax=ax0)\n",
    "plot_confusion_matrix(gridsearch, X_test, y_test, ax=ax1)\n",
    "ax0.title.set_text('Train Confusion Matrix')\n",
    "ax1.title.set_text('Test Confusion Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd7271d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "train_preds = gridsearch.predict(X_train)\n",
    "test_preds = gridsearch.predict(X_test)\n",
    "\n",
    "print(classification_report(y_train, train_preds))\n",
    "print(classification_report(y_test, test_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49345c5e",
   "metadata": {},
   "source": [
    "<a id=\"6.3\"></a>\n",
    "# 6.3 K-Nearest Neighbors\n",
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb38a14",
   "metadata": {},
   "source": [
    "<a id=\"6.3.1\"></a>\n",
    "## 6.3.1 K-Nearest Neighbors\n",
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc5ad73",
   "metadata": {},
   "source": [
    "<a id=\"6.3.1.a\"></a>\n",
    "## 6.3.1 Train model\n",
    "****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee447e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n",
    "clf = neighbors.KNeighborsClassifier(n_neighbors = 1, p = 2)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb053711",
   "metadata": {},
   "source": [
    "<a id=\"6.3.1.b\"></a>\n",
    "## 6.3.1 Evaluating a classification model\n",
    "****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306f059b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "fig, (ax0, ax1) = plt.subplots(1, 2, figsize=(20, 8))\n",
    "plot_confusion_matrix(clf, X_train, y_train, ax=ax0)\n",
    "plot_confusion_matrix(clf, X_test, y_test, ax=ax1)\n",
    "ax0.title.set_text('Train Confusion Matrix')\n",
    "ax1.title.set_text('Test Confusion Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee10266",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "train_preds = clf.predict(X_train)\n",
    "test_preds = clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_train, train_preds))\n",
    "print(classification_report(y_test, test_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f4e448",
   "metadata": {},
   "source": [
    "<a id=\"6.3.2\"></a>\n",
    "## 6.3.1 K-Nearest Neighbors with GridSearchCV\n",
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52bc6fe8",
   "metadata": {},
   "source": [
    "<a id=\"6.3.2.a\"></a>\n",
    "## 6.3.1 Train model\n",
    "****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c9d921",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# define the parameters want to search through\n",
    "knn_grid = {'n_neighbors': [1, 2, 3, 4, 5],\n",
    "           'weights': ['uniform', 'distance']}\n",
    "\n",
    "# instantiate gridsearch\n",
    "knn_search = GridSearchCV(KNeighborsClassifier(), knn_grid, scoring='accuracy', verbose=1)\n",
    "\n",
    "# fit the grid\n",
    "knn_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c6c6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b94004",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = knn_search.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1b22b2",
   "metadata": {},
   "source": [
    "<a id=\"6.3.2.b\"></a>\n",
    "## 6.3.2 Evaluating a classification model\n",
    "****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb685ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "fig, (ax0, ax1) = plt.subplots(1, 2, figsize=(20, 8))\n",
    "plot_confusion_matrix(knn_search, X_train, y_train, ax=ax0)\n",
    "plot_confusion_matrix(knn_search, X_test, y_test, ax=ax1)\n",
    "ax0.title.set_text('Train Confusion Matrix')\n",
    "ax1.title.set_text('Test Confusion Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a9cfbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_train, train_preds))\n",
    "print(classification_report(y_test, test_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732308c5",
   "metadata": {},
   "source": [
    "<a id=\"6.4\"></a>\n",
    "# 6.4 Ensemble Learning\n",
    "*****\n",
    "In statistics and machine learning, ensemble methods use multiple learning algorithms to obtain better predictive performance than could be obtained from any of the constituent learning algorithms alone. \n",
    "\n",
    "There are two types of ensemple learnings. \n",
    "\n",
    "**Bagging/Averaging Methods**\n",
    "> In averaging methods, the driving principle is to build several estimators independently and then to average their predictions. On average, the combined estimator is usually better than any of the single base estimator because its variance is reduced.\n",
    "\n",
    "**Boosting Methods**\n",
    "> The other family of ensemble methods are boosting methods, where base estimators are built sequentially and one tries to reduce the bias of the combined estimator. The motivation is to combine several weak models to produce a powerful ensemble."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513133e3",
   "metadata": {},
   "source": [
    "<a id=\"6.4.1\"></a>\n",
    "## 6.4.1 Bagging Classifier\n",
    "*****\n",
    "<a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html\">Bagging Classifier</a>(Bootstrap Aggregating) is the ensemble method that involves manipulating the training set by resampling and running algorithms on it. Let's do a quick review:\n",
    "* Bagging classifier uses a process called bootstrapped dataset to create multiple datasets from one original dataset and runs algorithm on each one of them. Here is an image to show how bootstrapped dataset works. \n",
    "<img src=\"https://uc-r.github.io/public/images/analytics/bootstrap/bootstrap.png\" width=\"600\">\n",
    "<h4 align=\"center\">Resampling from original dataset to bootstrapped datasets</h4>\n",
    "<h4 align=\"right\">Source: https://uc-r.github.io</h4>\n",
    "\n",
    "\n",
    "* After running a learning algorithm on each one of the bootstrapped datasets, all models are combined by taking their average. the test data/new data then go through this averaged classifier/combined classifier and predict the output. \n",
    "\n",
    "Here is an image to make it clear on how bagging works, \n",
    "<img src=\"https://prachimjoshi.files.wordpress.com/2015/07/screen_shot_2010-12-03_at_5-46-21_pm.png\" width=\"600\">\n",
    "<h4 align=\"right\">Source: https://prachimjoshi.files.wordpress.com</h4>\n",
    "Please check out [this](https://www.kaggle.com/masumrumi/bagging-with-titanic-dataset) kernel if you want to find out more about bagging classifier. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc4ffde",
   "metadata": {},
   "source": [
    "<a id=\"6.4.1.a\"></a>\n",
    "## 6.4.1.a Train Model\n",
    "*****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41c30fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "n_estimators = [10,30,50,70,80,150,160, 170,175,180,185];\n",
    "cv = StratifiedShuffleSplit(n_splits=10, test_size=.30, random_state=15)\n",
    "\n",
    "parameters = {'n_estimators':n_estimators,\n",
    "              \n",
    "        }\n",
    "grid = GridSearchCV(BaggingClassifier(base_estimator= None, ## If None, then the base estimator is a decision tree.\n",
    "                                      bootstrap_features=False),\n",
    "                                 param_grid=parameters,\n",
    "                                 cv=cv,\n",
    "                                 n_jobs = -1)\n",
    "grid.fit(X,y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4705df66",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (grid.best_score_)\n",
    "print (grid.best_params_)\n",
    "print (grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8900ad3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bagging_grid = grid.best_estimator_\n",
    "bagging_grid.score(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebc624f",
   "metadata": {},
   "source": [
    "<a id=\"6.4.1.b\"></a>\n",
    "## 6.4.1.b Evaluating a classification model\n",
    "*****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202bbd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "fig, (ax0, ax1) = plt.subplots(1, 2, figsize=(20, 8))\n",
    "plot_confusion_matrix(grid, X_train, y_train, ax=ax0)\n",
    "plot_confusion_matrix(grid, X_test, y_test, ax=ax1)\n",
    "ax0.title.set_text('Train Confusion Matrix')\n",
    "ax1.title.set_text('Test Confusion Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a06790a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "train_preds = grid.predict(X_train)\n",
    "test_preds = grid.predict(X_test)\n",
    "\n",
    "print(classification_report(y_train, train_preds))\n",
    "print(classification_report(y_test, test_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5c33f1",
   "metadata": {},
   "source": [
    "<a id=\"6.4.1.c\"></a>\n",
    "## 6.4.1.c Comparing Pro and Cons\n",
    "*****\n",
    "<h3>Why use Bagging? (Pros and cons)</h3>\n",
    "Bagging works best with strong and complex models(for example, fully developed decision trees). However, don't let that fool you to thinking that similar to a decision tree, bagging also overfits the model. Instead, bagging reduces overfitting since a lot of the sample training data are repeated and used to create base estimators. With a lot of equally likely training data, bagging is not very susceptible to overfitting with noisy data, therefore reduces variance. However, the downside is that this leads to an increase in bias.\n",
    "\n",
    "****\n",
    "<h4>Random Forest VS. Bagging Classifier</h4>\n",
    "\n",
    "If some of you are like me, you may find Random Forest to be similar to Bagging Classifier. However, there is a fundamental difference between these two which is **Random Forests ability to pick subsets of features in each node.** I will elaborate on this in a future update."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee68714e",
   "metadata": {},
   "source": [
    "<a id=\"6.4.2\"></a>\n",
    "## 6.4.2 AdaBoost Classifier\n",
    "*****\n",
    "AdaBoost is another <b>ensemble model</b> and is quite different than Bagging. Let's point out the core concepts. \n",
    "> AdaBoost combines a lot of \"weak learners\"(they are also called stump; a tree with only one node and two leaves) to make classifications.\n",
    "\n",
    "> This base model fitting is an iterative process where each stump is chained one after the other; <b>It cannot run in parallel.</b>\n",
    "\n",
    "> <b>Some stumps get more say in the final classifications than others.</b> The models use weights that are assigned to each data point/raw indicating their \"importance.\" Samples with higher weight have a higher influence on the total error of the next model and gets more priority. The first stump starts with uniformly distributed weight which means, in the beginning, every datapoint have an equal amount of weights. \n",
    "\n",
    "> <b>Each stump is made by talking the previous stump's mistakes into account.</b> After each iteration weights gets re-calculated in order to take the errors/misclassifications from the last stump into consideration. \n",
    "\n",
    "> The final prediction is typically constructed by a weighted vote where weights for each base model depends on their training errors or misclassification rates. \n",
    "\n",
    "To illustrate what we have talked about so far let's look at the following visualization. \n",
    "\n",
    "<img src=\"https://cdn-images-1.medium.com/max/1600/0*paPv7vXuq4eBHZY7.png\">\n",
    "<h5 align=\"right\"> Source: Diogo(Medium)</h5>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Let's dive into each one of the nitty-gritty stuff about AdaBoost:\n",
    "***\n",
    "> <b>First</b>, we determine the best feature to split the dataset using Gini index(basics from decision tree). The feature with the lowest Gini index becomes the first stump in the AdaBoost stump chain(the lower the Gini index is, the better unmixed the label is, therefore, better split).\n",
    "***\n",
    "> <b>Secondly</b>, we need to determine how much say a stump will have in the final classification and how we can calculate that.\n",
    "* We learn how much say a stump has in the final classification by calculating how well it classified the samples (aka calculate the total error of the weight).\n",
    "* The <b>Total Error</b> for a stump is the sum of the weights associated with the incorrectly classified samples. For example, lets say, we start a stump with 10 datasets. The first stump will uniformly distribute an weight amoung all the datapoints. Which means each data point will have 1/10 weight. Let's say once the weight is distributed we run the model and find 2 incorrect predicitons. In order to calculate the total erorr we add up all the misclassified weights. Here we get 1/10 + 1/10 = 2/10 or 1/5. This is our total error. We can also think about it\n",
    "\n",
    "\n",
    "$$ \\epsilon_t = \\frac{\\text{misclassifications}_t}{\\text{observations}_t} $$\n",
    "\n",
    "\n",
    "* Since the weight is uniformly distributed(all add up to 1) among all data points, the total error will always be between 0(perfect stump) and 1(horrible stump).\n",
    "* We use the total error to determine the amount of say a stump has in the final classification using the following formula\n",
    " \n",
    "\n",
    "$$ \\alpha_t = \\frac{1}{2}ln \\left(\\frac{1-\\epsilon_t}{\\epsilon_t}\\right) \\text{where } \\epsilon_t < 1$$\n",
    "\n",
    "\n",
    "Where $\\epsilon_t$ is the misclassification rate for the current classifier:\n",
    "\n",
    "\n",
    "$$ \\epsilon_t = \\frac{\\text{misclassifications}_t}{\\text{observations}_t} $$\n",
    "\n",
    "\n",
    "Here...\n",
    "* $\\alpha_t$ = Amount of Say\n",
    "* $\\epsilon_t$ = Total error\n",
    "\n",
    "\n",
    "\n",
    "We can draw a graph to determine the amount of say using the value of total error(0 to 1)\n",
    "\n",
    "<img src=\"http://chrisjmccormick.files.wordpress.com/2013/12/adaboost_alphacurve.png\">\n",
    "<h5 align=\"right\"> Source: Chris McCormick</h5>\n",
    "\n",
    "* The blue line tells us the amount of say for <b>Total Error(Error rate)</b> between 0 and 1. \n",
    "* When the stump does a reasonably good job, and the <b>total error</b> is minimal, then the <b>amount of say(Alpha)</b> is relatively large, and the alpha value is positive. \n",
    "* When the stump does an average job(similar to a coin flip/the ratio of getting correct and incorrect ~50%/50%), then the <b>total error</b> is ~0.5. In this case the <b>amount of say</b> is <b>0</b>.\n",
    "* When the error rate is high let's say close to 1, then the <b>amount of say</b> will be negative, which means if the stump outputs a value as \"survived\" the included weight will turn that value into \"not survived.\"\n",
    "\n",
    "P.S. If the <b>Total Error</b> is 1 or 0, then this equation will freak out. A small amount of error is added to prevent this from happening. \n",
    " \n",
    " ***\n",
    "> <b>Third</b>, We need to learn how to modify the weights so that the next stump will take the errors that the current stump made into account. The pseducode for calculating the new sample weight is as follows. \n",
    "\n",
    "\n",
    "$$ New Sample Weight = Sample Weight + e^{\\alpha_t}$$\n",
    "\n",
    "Here the $\\alpha_t(AmountOfSay)$ can be positive or negative depending whether the sample was correctly classified or misclassified by the current stump. We want to increase the sample weight of the misclassified samples; hinting the next stump to put more emphasize on those. Inversely, we want to decrease the sample weight of the correctly classified samples; hinting the next stump to put less emphasize on those. \n",
    "\n",
    "The following equation help us to do this calculation. \n",
    "\n",
    "$$ D_{t+1}(i) = D_t(i) e^{-\\alpha_t y_i h_t(x_i)} $$\n",
    "\n",
    "Here, \n",
    "* $D_{t+1}(i)$ = New Sample Weight. \n",
    "* $D_t(i)$ = Current Sample weight.\n",
    "* $\\alpha_t$ = Amount of Say, alpha value, this is the coefficient that gets updated in each iteration and \n",
    "* $y_i h_t(x_i)$ = place holder for 1 if stump correctly classified, -1 if misclassified. \n",
    "\n",
    "Finally, we put together the combined classifier, which is \n",
    "\n",
    "$$ AdaBoost(X) = sign\\left(\\sum_{t=1}^T\\alpha_t h_t(X)\\right) $$ \n",
    "\n",
    "Here, \n",
    "\n",
    "$AdaBoost(X)$ is the classification predictions for $y$ using predictor matrix $X$\n",
    "\n",
    "$T$ is the set of \"weak learners\"\n",
    "\n",
    "$\\alpha_t$ is the contribution weight for weak learner $t$\n",
    "\n",
    "$h_t(X)$ is the prediction of weak learner $t$\n",
    "\n",
    "and $y$ is binary **with values -1 and 1**\n",
    "\n",
    "\n",
    "P.S. Since the stump barely captures essential specs about the dataset, the model is highly biased in the beginning. However, as the chain of stumps continues and at the end of the process, AdaBoost becomes a strong tree and reduces both bias and variance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffaef30",
   "metadata": {},
   "source": [
    "<a id=\"5.4.2.a\"></a>\n",
    "## 5.4.2.a Train Model\n",
    "*****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9710f98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "n_estimators = [100,140,145,150,160, 170,175,180,185];\n",
    "cv = StratifiedShuffleSplit(n_splits=10, test_size=.30, random_state=15)\n",
    "learning_r = [0.1,1,0.01,0.5]\n",
    "\n",
    "parameters = {'n_estimators':n_estimators,\n",
    "              'learning_rate':learning_r\n",
    "              \n",
    "        }\n",
    "grid = GridSearchCV(AdaBoostClassifier(base_estimator= None, ## If None, then the base estimator is a decision tree.\n",
    "                                     ),\n",
    "                                 param_grid=parameters,\n",
    "                                 cv=cv,\n",
    "                                 n_jobs = -1)\n",
    "grid.fit(X,y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847da9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (grid.best_score_)\n",
    "print (grid.best_params_)\n",
    "print (grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431e73ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "adaBoost_grid = grid.best_estimator_\n",
    "adaBoost_grid.score(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fc2e26",
   "metadata": {},
   "source": [
    "<a id=\"5.4.2.b\"></a>\n",
    "## 5.4.2.b Evaluating a classification model\n",
    "*****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8825b2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "fig, (ax0, ax1) = plt.subplots(1, 2, figsize=(20, 8))\n",
    "plot_confusion_matrix(grid, X_train, y_train, ax=ax0)\n",
    "plot_confusion_matrix(grid, X_test, y_test, ax=ax1)\n",
    "ax0.title.set_text('Train Confusion Matrix')\n",
    "ax1.title.set_text('Test Confusion Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5898187d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "train_preds = grid.predict(X_train)\n",
    "test_preds = grid.predict(X_test)\n",
    "\n",
    "print(classification_report(y_train, train_preds))\n",
    "print(classification_report(y_test, test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6adc176a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2a0dd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebd8dc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c4b6b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5ae4a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f6f045",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4303f576",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a1309b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5a0d08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726a24da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7873b752",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf5c36c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9931d4df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a8b83b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd05a464",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba8dd9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05113a4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b896c43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3f3409",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747e882b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00215d1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72dc060c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825a920a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c38e67f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd67a990",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385937ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e7b20c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03034c3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f9f5ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8365a2cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65f5f2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6fc9a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af79ebd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c2acc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af1c83b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95640d1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34551e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6044eec4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bcfc9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f9a8ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b0c907",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c77fbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
